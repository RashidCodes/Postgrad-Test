{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Is postgraduate degree necessary to be a Data Scientist?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data science is an interdisciplinary field which combines the power of statistics and computer science to make sense of massive stores of data. Companies are willing to pay top dollar for experts that can assist with decision making using data. Data science is a profession which requires its practitioners to be skilled in multiple areas such as programming and statistics to name a few <i>(Oracle.com, 2014)</i>. For this reason, prerequisites outlined by companies for data professional positions can be very daunting to the aspiring data professional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further emphasize on the subject, below are posts about an open data science position at Google <i>[ref in ass1]</i> and Facebook <i>[ref in ass1].</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Minimum Qualifications in Google</b>\n",
    "\n",
    "- Master’s degree in Operations Research, Industrial Engineering, Statistics, related field, or equivalent practical experience.\n",
    "- 2 years of relevant work experience (example, as a data scientist) or equivalent. Analytical engagements outside class work while at school can also be included.\n",
    "- Experience with statistical software (example R, Python) and database languages (e.g. SQL)\n",
    "\n",
    "<b>Preferred Qualifications</b>\n",
    "\n",
    "- PhD in Operations Research, Industrial Engineering, Statistics or related field.\n",
    "- 4 years of relevant work experience( e.g. as a data scientist), including experience applying advanced analytics to planning and infrastructure problems.\n",
    "- Experience designing and building statistical forecasting models.\n",
    "- Experience designing and building machine learning models.\n",
    "- Excellent problem-framing, problem-solving and project management skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Minimum Qualifications at Facebook</b>\n",
    "\n",
    "- 5+ years of hands-on data science experience, Data analysis skill, willing to get your hands dirty with data.\n",
    "- Expert knowledge of SQL, Python, R.\n",
    "- Experience on working with multiple cross functional partners and influence decision making based on data.\n",
    "- Experience initiating and driving projects to completion with minimal guidance.\n",
    "- Experimentation – AB testing.\n",
    "\n",
    "\n",
    "\n",
    "<b>Preferred Qualifications</b>\n",
    "\n",
    "- Educational background in Computer Science, Math, Physics, Engineering, or related quantitative field.\n",
    "- Expert in experimentation.\n",
    "- Experience with large data sets and distributed computing (Hive/Hadoop).\n",
    "- Exposure to large scale infrastructure systems, comfortable with technical discussions.\n",
    "- Excellent customer service and team collaboration skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, the prerequisites aforementioned involve having high educational qualifications because the companies in question are Google and Facebook. This project seeks to determine if most data scientists possess at least a postgraduate degree using statistical methods. The project also seeks to find the proportion of data science professionals currently working in industry that possess a postgraduate degree in fields such as computer science, statistics, engineering, mathematics or any related field. The prerequisites aforementioned by Google and Facebook will then be evaluated against the project findings. The results garnered from this project can also help aspirants prepare for their future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Curation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkedIn is a very popular social website for professionals in all fields. The purpose of LinkedIn is to engender social networking and career development <i>(Johnson, n.d.)</i>. The data about randomly selected professionals are scraped using the python programming language. This section describes how the language is used to create the second dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>API Design</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data curation process heavily relies on the <code>Scraper</code>, <code>ScrapeLinkedin</code> and <code>ScrapeLinkedInM</code> classes. These 2 classes are created because it is arduous to manually collect links to profiles of data scientists.\n",
    "\n",
    "The <code>Scraper</code> class is used to scrape data from <b>Yahoo</b>, <b>Bing,</b> and <b>Google.</b> The scraped data is stored in a text file specified using the <code>file_name</code> attribute. The file is created if it does not exist however, if the file already exists then the scraped data is appended to the content of the file. This behavior can be changed using the <code>mode</code> attribute of the <code>Scraper</code>.If the <code>num_of_pages</code> exceeds the actual number of pages containing results (search engine results are grouped into pages), the scraper must be manually halted. A scraper scrapes from <b>Google</b> by default. This behaviour can be altered using the <code>search_engine</code> attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building the <code>Scraper</code> class.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import Firefox\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randrange\n",
    "from math import ceil\n",
    "import requests\n",
    "\n",
    "class Scraper:\n",
    "    \n",
    "    \"\"\"Scrape links to LinkedIn profiles from the results of search engines - Google, Bing and Yahoo.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    file_name: String\n",
    "    Name of the file where the links will be stored.\n",
    "    \n",
    "    mode: String\n",
    "    Valid modes are 'a', 'w'.\n",
    "    'a' = append mode (new data will be appended)\n",
    "    'w' = write mode (new data will overwrite existing data)\n",
    "    \n",
    "    retry: int\n",
    "    Number of times a request will be made after a timeout occurs.\n",
    "    \n",
    "    search_engine : String\n",
    "    The preferred search engine. By default, the google search engine is used.\n",
    "    Valid search engines:\n",
    "        \"Google\", \"Bing\", \"Yahoo\"\n",
    "    \n",
    "    sleep_time: int\n",
    "    Sleep time of the scraper. Random numbers between 60 and 100 are chosen by default.\n",
    "    \n",
    "    num_of_pages: int\n",
    "    The number of pages to scrape. Each page contains a set of links.\n",
    "    \n",
    "    domains: String\n",
    "    The path of a text file that contains necessary linked domains.\n",
    "    \n",
    "    time_out: int\n",
    "    Waiting time before another request is made when a timeout occurs.\n",
    "    \n",
    "    \n",
    "    Methods\n",
    "    --------\n",
    "    scrape: Initiates a scraping process\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_name=\"scraped.txt\", mode=\"a\", retry=5, search_engine=\"Google\", \\\n",
    "                 sleep_time=randrange(60, 100, 2), num_of_pages=3, \\\n",
    "                 domains=\"linkedInDomains.txt\", time_out=500):\n",
    "        \n",
    "        self._file_name = file_name\n",
    "        self._mode = mode\n",
    "        self._retry = retry\n",
    "        self._search_engine = search_engine\n",
    "        self._sleep_time = sleep_time\n",
    "        self._num_of_pages = num_of_pages\n",
    "        self._time_out = time_out\n",
    "        self._linkedInDomains = domains\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Scraper(file_name={}, mode={}, search_engine={}, domains={})\"\\\n",
    "                .format(self._file_name, self._mode, self._search_engine, self._linkedInDomains)\n",
    "        \n",
    "    \n",
    "    def extract_link(self, link):\n",
    "        \"\"\"\n",
    "        Extract the href of a given link tag\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        link: bs4.element.Tag\n",
    "        A link tag eg. <a href=\"https://rashid.com\">Moh</a>\n",
    "        \"\"\"            \n",
    "\n",
    "        ## check if a link contains one of the domains\n",
    "        if self.LINKED_IN_DOMAINS:\n",
    "            for domain in self.LINKED_IN_DOMAINS:\n",
    "                if domain in str(link):\n",
    "                    href = link.get('href')\n",
    "                    return href\n",
    "\n",
    "                continue\n",
    "        else:\n",
    "            print(\"Specify a path to valid linkedin domains.\")\n",
    "    \n",
    "    \n",
    "    def set_domains(self): \n",
    "        \"\"\"Set the linkedin domains\"\"\"\n",
    "        with open(self._linkedInDomains, \"r\") as domains:\n",
    "            self.LINKED_IN_DOMAINS = [domain.strip(\"\\n\") for domain in domains.readlines()]\n",
    "        \n",
    "            \n",
    "            \n",
    "    @staticmethod\n",
    "    def save_links(file_name, mode, linkedin_links):\n",
    "        \"\"\" Save scraped links in a single document\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_name: String\n",
    "        Name of the document\n",
    "        \n",
    "        mode: String\n",
    "            Valid modes:\n",
    "                \"a\" = append mode (appends data to file_name)\n",
    "                \"w\" = write mode (overwrites existing data in file_name if file_name exists)\n",
    "                \n",
    "        linkedin_links: list\n",
    "        Scraped linkedin profile links\n",
    "        \n",
    "        \"\"\"\n",
    "        print('Saving links to {}'.format(file_name))\n",
    "        with open(file_name, mode) as file:\n",
    "            for link in linkedin_links:\n",
    "                print(link)\n",
    "                file.write(link + \"\\n\")\n",
    "        print(\"Done saving\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def combine_links(*documents, finalDoc=\"finalURLS.txt\"):\n",
    "        \"\"\"Consolidate data from multiple documents into a single document\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        args*: String\n",
    "        All documents\n",
    "\n",
    "        finalDoc: String\n",
    "        Document of consolidated links\n",
    "        \"\"\"\n",
    "        links = set()\n",
    "\n",
    "        for document in documents:\n",
    "            with open(document, 'r') as file:\n",
    "                for link in file.readlines():\n",
    "                    links.add(link)\n",
    "\n",
    "        print(\"Done combining\")\n",
    "        print(\"Number of unique links: {}\".format(len(links)))\n",
    "        print()\n",
    "        print(\"Saving to {}...\".format(finalDoc))\n",
    "\n",
    "        with open(finalDoc, 'a') as doc:\n",
    "            for link in links:\n",
    "                doc.write(link)\n",
    "\n",
    "        print(\"Finished saving.\")\n",
    "        print(\"You have successfully garnered the links of {} linkedin profiles\".format(len(links)))\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def length(file):\n",
    "        \"\"\"Compute the number of unique links in a single document.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file : String\n",
    "        Document name\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as profiles:\n",
    "            data = set([profile.strip(\"\\n\") for profile in profiles.readlines()])\n",
    "\n",
    "        return len(data)\n",
    "    \n",
    "    \n",
    "    def get_length(self, file=None):\n",
    "        \"\"\"Get the number of unique links\"\"\"\n",
    "        if file:\n",
    "            return self.length(file)\n",
    "            \n",
    "        return self.length(self._file_name)\n",
    "        \n",
    "            \n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "        Scrape data from yahoo, bing or google. By default, the data is stored in a document with name\n",
    "        - scraped.txt.\n",
    "        \n",
    "        \"\"\"\n",
    "        driver = Firefox(executable_path='./geckodriver')\n",
    "        self.page = 0\n",
    "        self.start = 0\n",
    "        self.TRY = 0\n",
    "        \n",
    "        self.set_domains()\n",
    "            \n",
    "              \n",
    "            \n",
    "        def scrape_pages(self):\n",
    "\n",
    "            print()\n",
    "            print(\"Started scraping\")\n",
    "\n",
    "            try:\n",
    "                address = self.url.format(self.start)\n",
    "                driver.get(address)\n",
    "                self.start += 10\n",
    "\n",
    "            except TimeoutException:\n",
    "                self.TRY += 1\n",
    "                print(\"The request timed out. Another request will be made in approximately {} {}\"\\\n",
    "                      .format(ceil(self._time_out/60), \"minutes\" if ceil(self._time_out / 60) > 1 else \"minute\"))\n",
    "\n",
    "                time.sleep(self._time_out)\n",
    "\n",
    "                if self.TRY <= self._retry:\n",
    "                    print(\"Restarting...\")\n",
    "                    scrape_pages(self)\n",
    "                    return\n",
    "                print(\"Maximum number of retries reached.\")\n",
    "\n",
    "\n",
    "            except Exception:\n",
    "                self.TRY += 1\n",
    "\n",
    "                print(\"Unable to navigate to {}. This may probably be due to a problem with your internet connection.\".format(address))\n",
    "\n",
    "                print(\"Another request will be made in approximately {} {}\"\\\n",
    "                      .format(ceil(self._time_out/60), \"minutes\" if ceil(self._time_out / 60) > 1 else \"minute\"))\n",
    "\n",
    "                time.sleep(self._time_out)\n",
    "                if self.TRY <= self._retry:\n",
    "                    print(\"Restarting...\")\n",
    "                    scrape_pages(self)\n",
    "                    return\n",
    "\n",
    "                print(\"Maximum number of retries reached. Check your internet connection and try again.\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    results = driver.find_element_by_css_selector(self.results_tag)\n",
    "\n",
    "                except Exception:\n",
    "                    print(\"The results could not be found. Make sure the results tag is correct.\")\n",
    "                    driver.quit()\n",
    "\n",
    "                else:\n",
    "                    soup = BeautifulSoup(results.get_attribute('innerHTML'))\n",
    "                    links = soup.find_all('a')\n",
    "                    linkedin_links = [self.extract_link(link) for link in links if self.extract_link(link) != None]\n",
    "\n",
    "\n",
    "                    # save links to file\n",
    "                    self.save_links(self._file_name, self._mode, linkedin_links)\n",
    "\n",
    "                    print()\n",
    "                    print(\"Finished scraping session.\")\n",
    "                    print()\n",
    "\n",
    "                    self.page += 1\n",
    "\n",
    "                    if (self.page < self._num_of_pages):\n",
    "                        print(\"Page Number: {}\".format(self.page+1))\n",
    "                        print(\"Next scraping session starts in approximately {} {}\".format(ceil(self._sleep_time / 60), \"minutes\" if ceil(self._sleep_time / 60) > 1 else \"minute\"))\n",
    "                        time.sleep(self._sleep_time)\n",
    "                        scrape_pages(self)\n",
    "                        return\n",
    "\n",
    "                    print(\"Finished scraping {}.\".format(self._search_engine))\n",
    "                    print(\"A total of {} unique links were captured\".format(self.get_length()))\n",
    "                    driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "        def scrape_yahoo(self):\n",
    "\n",
    "            QUERY = 'site:linkedin.com/in/ and \"data scientist\"'\n",
    "            SEARCH_ENGINE = \"https://au.search.yahoo.com/\"\n",
    "\n",
    "\n",
    "\n",
    "            def scrape_(self):\n",
    "\n",
    "                from random import randrange\n",
    "                from math import ceil\n",
    "\n",
    "                print()\n",
    "                print(\"Started scraping\")\n",
    "                \n",
    "                response = requests.get(driver.current_url)\n",
    "                \n",
    "                if(response.status_code == 200):\n",
    "                    soup = BeautifulSoup(response.content)\n",
    "                    links = soup.find_all('a')\n",
    "                    linkedIn_links = [self.extract_link(link) for link in links if self.extract_link(link) != None]\n",
    "\n",
    "                    # save links to file\n",
    "                    self.save_links(self._file_name, self._mode, linkedIn_links)             \n",
    "\n",
    "                    print(\"Finished scraping session.\")\n",
    "                    print()\n",
    "\n",
    "                    try:\n",
    "                        next_button = driver.find_element_by_class_name(\"next\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"The next button was not found. Make sure the tag is correct\")\n",
    "                        print(e)\n",
    "                        driver.quit()\n",
    "\n",
    "                    else:\n",
    "                        # increase page number\n",
    "                        self.page += 1\n",
    "                        if(self.page < self._num_of_pages):\n",
    "                            print(\"Next scraping session starts in approximately {} minutes\"\\\n",
    "                                  .format(ceil(self._sleep_time / 60)))\n",
    "                            time.sleep(self._sleep_time)\n",
    "                            next_button.click()\n",
    "                            scrape_(self)\n",
    "                            return\n",
    "\n",
    "                        print(\"Finished scraping {}.\".format(self._search_engine))\n",
    "                        print(\"A total of {} unique links were captured\".format(self.get_length()))\n",
    "                        driver.quit()\n",
    "                        \n",
    "                elif(response.status_code == 400):\n",
    "                    self.TRY += 1\n",
    "                    print('Unable to make request to {}'.format(driver.current_url))\n",
    "                    print(\"Sleeping for approximately {} minutes\".format(ceil(self._time_out/60)))\n",
    "                    time.sleep(self._time_out)\n",
    "                    print(\"Resuming scraping...\")\n",
    "                    if self.TRY <= self._retry:\n",
    "                        print(\"Restarting...\")\n",
    "                        scrape_(self)\n",
    "                        return\n",
    "\n",
    "                    print(\"Maximum number of retries reached. Check your internet connection and try again.\")\n",
    "                    \n",
    "\n",
    "\n",
    "            # navigate to the search engine\n",
    "            def navigate():\n",
    "\n",
    "                try:\n",
    "                    driver.get(SEARCH_ENGINE)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Unable to navigate to {}\".format(SEARCH_ENGINE))\n",
    "                    print(e)\n",
    "                    driver.quit()\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        search_bar = driver.find_element_by_id(\"yschsp\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"Unable to find search bar. Make sure the tag is correct.\")\n",
    "                        print(e)\n",
    "                        driver.quit()\n",
    "\n",
    "                    else:\n",
    "                        search_bar.send_keys(QUERY)\n",
    "                        search_bar.send_keys(Keys.RETURN)\n",
    "                        time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "            navigate()\n",
    "            scrape_(self)\n",
    "            \n",
    "\n",
    "        if self._search_engine.lower() == \"google\":\n",
    "            self.url = \"https://www.google.com/search?q=site:linkedin.com/in/+and+%22data+scientist&sxsrf=ALeKk0208dEtnt4b3nwIuibK2w5dgJZICg:1600239312247&ei=0LZhX9fgDteb9QOQppi4DQ&start={}&sa=N&ved=2ahUKEwjXiIz-i-3rAhXXTX0KHRATBtcQ8NMDegQICxBB&biw=1680&bih=938\"\n",
    "            self.results_tag = \"#res\"\n",
    "            scrape_pages(self)\n",
    "\n",
    "        elif self._search_engine.lower() == \"bing\":\n",
    "            self.url = \"https://www.bing.com/search?q=site%3alinkedin.com%2fin%2f+AND+%22data+scientist%22&search=&first={}&FORM=PERE3\".strip()\n",
    "            self.results_tag = \"#b_results\"\n",
    "            scrape_pages(self)\n",
    "\n",
    "        elif self._search_engine.lower() == \"yahoo\":\n",
    "            scrape_yahoo(self)\n",
    "\n",
    "        else:\n",
    "            print(\"Select a valid search engine\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the <code>Scraper</code> class.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the <code>Scraper</code> class is briefly highlighted. The documentation can be perused for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#005b96;\">Bing</h4>\n",
    "\n",
    "```bash\n",
    "from Scraper import Scraper\n",
    "bing = Scraper(\"bingLinkedInURLS.txt\", search_engine=\"Bing\")\n",
    "bing.scrape()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#005b96;\">Google</h4>\n",
    "\n",
    "```bash\n",
    "from Scraper import Scraper\n",
    "google = Scraper(\"googleLinkedInURLS.txt\", sleep_time=randrange(80, 100, 2))\n",
    "google.scrape()\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#005b96;\">Yahoo</h4>\n",
    "\n",
    "```bash\n",
    "from Scraper import Scraper\n",
    "yahoo = Scraper(\"yahooLinkedInURLS.txt\", search_engine=\"Yahoo\")\n",
    "yahoo.scrape()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#011f4b;\">Combine the results after a scraping session.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a scraping session, i.e. after scraping from Bing, Yahoo or Google, the data in different files can be  consolidated into a single file with the <code>combine_links</code> method of any instance.\n",
    "\n",
    "```bash\n",
    "yahoo.combine_links(\"bingLinkedInURLS.txt\", \"googleLinkedInURLS.txt\", \"yahooLinkedInURLS.txt\")\n",
    "```\n",
    "\n",
    "```bash\n",
    "google.combine_links(\"bingLinkedInURLS.txt\", \"googleLinkedInURLS.txt\", \"yahooLinkedInURLS.txt\")\n",
    "```\n",
    "\n",
    "```bash\n",
    "bing.combine_links(\"bingLinkedInURLS.txt\", \"googleLinkedInURLS.txt\", \"yahooLinkedInURLS.txt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#011f4b;\">Results</h4>\n",
    "\n",
    "The <code>get_length</code> method is used to get the number of unique linkedin profiles a scraper successfully scraped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>get_length</code> method returns the amount of unique data that was scraped.\n",
    "\n",
    "```bash\n",
    ">>> yahoo.get_length()\n",
    ">>> 23\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building the <code>ScrapeLinkedIn</code> class.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>ScrapeLinkedin</code> class is used to scrape the data of a LinkedIn user. The scraped data can also be persisted in a local SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "class ScrapeLinkedin:\n",
    "    \"\"\"Scrape the data of a linkedin member with your linkedin profile.\n",
    "    \n",
    "    ======\n",
    "     NOTE\n",
    "    ======\n",
    "    THIS IS A BREACH OF THE TERMS AND CONDITIONS ASSOCIATED WITH THE USAGE OF LINKEDIN. YOUR ACCOUNT WILL BE\n",
    "    RESTRICTED IF SUSPICIOUS ACTIVITY IS DETECTED ON THE LINKEDIN WEBSITE.\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    email: String\n",
    "    Your email address eg. yourEmail@email.com\n",
    "\n",
    "    password: String\n",
    "    Your password\n",
    "\n",
    "    profile: String\n",
    "    The link to a member's linkedin profile\n",
    "\n",
    "    Id: String\n",
    "    A unique identifier of the profile\n",
    "\n",
    "    db_path: String\n",
    "    The path of the SQLite database\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    >>> person = ScrapeLinkedin(\"yourEmail@email.com\", \"yourPassword\", \"https://somelinkedprofile.com\", \"dgsdgs\")\n",
    "    >>> person.scrape()\n",
    "    >>> person.get_name()\n",
    "    'Person name'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    URL = \"https://linkedin.com\"\n",
    " \n",
    "    def __init__(self, email, password, profile, Id, db_path=\"ScientistsDB.db\"):\n",
    "        self._email = email\n",
    "        self._password = password\n",
    "        self._db_path = db_path\n",
    "        self._profile = profile\n",
    "        self._scientist_Id = Id\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ScrapeLinkedin({})\".format(self._profile)\n",
    "    \n",
    "    @staticmethod\n",
    "    def insert_scientist(db_path, Id, firstname, lastname, title, connections, location=None):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        data = (Id, firstname, lastname, title, location, connections)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.execute(\"INSERT INTO tblScientist VALUES (?, ?, ?, ?, ?, ?) \", data)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_experience(db_path, experiences):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblExperience VALUES (?, ?, ?, ?, ?, ?, ?)', experiences)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_education(db_path, education):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblEducation VALUES (?, ?, ?)', education)\n",
    "            conn.commit()\n",
    "            conn.close()  \n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_certification(db_path, certifications):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblCertificates VALUES (?, ?, ?)', certifications)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "     \n",
    "\n",
    "    @staticmethod\n",
    "    def extract_connections(conn_string):\n",
    "        if \"+\" in conn_string:\n",
    "            return int(conn_string.split(\"+\")[0])\n",
    "\n",
    "        return int(conn_string.split(\" \")[0])\n",
    "    \n",
    "\n",
    "    def parse_experience(self, item, scientist_Id):\n",
    "    \n",
    "        ## Not a timeline item\n",
    "        ul = item.find('ul')\n",
    "\n",
    "        if ul:\n",
    "            # get all timeline experiences\n",
    "            return self.get_more(item, scientist_Id)\n",
    "\n",
    "\n",
    "        # role\n",
    "        try:\n",
    "            role = item.find('h3').text.strip()\n",
    "\n",
    "        except:\n",
    "            role = None\n",
    "\n",
    "\n",
    "\n",
    "        # company\n",
    "        try:\n",
    "            company = item.find('p', class_=\"pv-entity__secondary-title\").contents\n",
    "\n",
    "        except:\n",
    "            company_name, employment_type = None, None\n",
    "\n",
    "        else:\n",
    "            company_name = company[0].strip()\n",
    "\n",
    "            try:\n",
    "                employment_type = company[1].text.strip()\n",
    "\n",
    "            except:\n",
    "                employment_type = None\n",
    "\n",
    "\n",
    "        # start and end dates\n",
    "        find_date_range = item.find('h4', class_=\"pv-entity__date-range\")\n",
    "        date_range = find_date_range.find_all('span')\n",
    "        split_dates = date_range[1].text.split(\"–\")\n",
    "\n",
    "        if(len(split_dates) == 1):\n",
    "            start_date = split_dates[0].strip()\n",
    "            end_date = None\n",
    "\n",
    "        else:\n",
    "            start_date, end_date = split_dates[0].strip(), split_dates[1].strip()\n",
    "\n",
    "\n",
    "        # location\n",
    "        try:\n",
    "            location = item.find('h4', class_=\"pv-entity__location\").find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "\n",
    "        return [(scientist_Id, company_name, employment_type, role, start_date, end_date, location)]\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def parse_education(edu, scientist_Id):\n",
    "        \"\"\"Parses education information\"\"\"\n",
    "\n",
    "        try:\n",
    "            school_name = edu.find('h3', class_ = 'pv-entity__school-name').text\n",
    "            \n",
    "        except:\n",
    "            school_name = None\n",
    "            \n",
    "        try:\n",
    "            list_of_paragraphs = edu.find('div', class_=\"pv-entity__degree-info\").find_all('p')\n",
    "            degree = \" \".join([p.find('span', class_=\"pv-entity__comma-item\").text for p in list_of_paragraphs]).strip()\n",
    "            \n",
    "        except:\n",
    "            degree = None\n",
    "\n",
    "        return [(scientist_Id, school_name, degree)]\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def parse_certificate(cert, scientist_Id):\n",
    "        \"\"\"Parse certificate information\"\"\"\n",
    "\n",
    "        try:\n",
    "            certificate = cert.find('h3', class_=\"t-16\").string.strip()\n",
    "        except:\n",
    "            certificate = None\n",
    "\n",
    "        try:\n",
    "            issuer = cert.find('div', class_=\"pv-certifications__summary-info\").find('p').contents[3].string.strip()\n",
    "        except:\n",
    "            issuer = None\n",
    "\n",
    "        return [(scientist_Id, certificate, issuer)]\n",
    "    \n",
    "    \n",
    "    def get_more(self, list_with_ul, scientist_Id):\n",
    "    \n",
    "        # timeline experiences\n",
    "        tl_exps = []\n",
    "\n",
    "        company_tag, ul_tag = list_with_ul.find('h3'), list_with_ul.find('ul')\n",
    "\n",
    "        if (company_tag and ul_tag) != None:\n",
    "            for list_tag in ul_tag.find_all('li'):\n",
    "                tl_exps.append(self.get_tl_exp(scientist_Id, company_tag, list_tag))\n",
    "\n",
    "            return tl_exps\n",
    "\n",
    "        print(\"No unordered list was detected\")\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tl_exp(scientist_Id, company_tag, item):\n",
    "    \n",
    "        # employement type\n",
    "        employment_type = None\n",
    "\n",
    "        # role\n",
    "        try:\n",
    "            role = item.find('h3').find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            role = None\n",
    "\n",
    "\n",
    "        # company\n",
    "        try:\n",
    "            company_name = company_tag.find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            company_name = None\n",
    "\n",
    "\n",
    "        # start and end dates\n",
    "        find_date_range = item.find('h4', class_=\"pv-entity__date-range\")\n",
    "        date_range = find_date_range.find_all('span')\n",
    "        split_dates = date_range[1].text.split(\"–\")\n",
    "\n",
    "        if(len(split_dates) == 1):\n",
    "            start_date = split_dates[0].strip()\n",
    "            end_date = None\n",
    "\n",
    "        else:\n",
    "            start_date, end_date = split_dates[0].strip(), split_dates[1].strip()\n",
    "            \n",
    "\n",
    "        # location\n",
    "        try:\n",
    "            location = item.find('h4', class_=\"pv-entity__location\").find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "\n",
    "        return (scientist_Id, company_name, employment_type, role, start_date, end_date, location)\n",
    "\n",
    "        \n",
    "    def scrape(self):     \n",
    "        try:\n",
    "            ## navigate to the linkedIN profile\n",
    "            linkedIn_driver = Chrome(executable_path='./chromedriver')\n",
    "            linkedIn_driver.get(self.URL)\n",
    "\n",
    "            # Sign In...\n",
    "            try:\n",
    "                toggle_button = linkedIn_driver.find_element_by_class_name('nav__button-secondary')\n",
    "                toggle_button.click()\n",
    "\n",
    "                time.sleep(2)\n",
    "\n",
    "                ## fill the form\n",
    "                try:\n",
    "                    ## find the username input \n",
    "                    username = linkedIn_driver.find_element_by_id('username')       \n",
    "\n",
    "                    ## find the password input\n",
    "                    password = linkedIn_driver.find_element_by_id('password')\n",
    "\n",
    "                    ## find the sign In button\n",
    "                    sign_in = linkedIn_driver.find_element_by_xpath('//button[@type=\"submit\"]')\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('An error occured, probably one of the inputs was not found. Check error log!')\n",
    "                    print()\n",
    "                    print(e)\n",
    "\n",
    "                ## no exception was raised, meaning all inputs were found\n",
    "                else:\n",
    "                    print(\"Entering your username...\")\n",
    "                    username.send_keys(self._email)\n",
    "\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    print('Entering your password...')\n",
    "                    password.send_keys(self._password)\n",
    "\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    print('Signing you in...')\n",
    "                    sign_in.click()\n",
    "                    print('Successfully signed in. Proceeding to another profile.')\n",
    "\n",
    "                    # stay on the home page for a few seconds\n",
    "                    time.sleep(5)\n",
    "\n",
    "                    ## navigate to the new profile\n",
    "                    try:       \n",
    "                        linkedIn_driver.get(self._profile)\n",
    "                        print(\"Scraping...\")\n",
    "                        \n",
    "                        # wait for the page to finish loading\n",
    "                        time.sleep(5)\n",
    "\n",
    "                        # for redirects\n",
    "                        if (self._profile != linkedIn_driver.current_url):\n",
    "                            linkedIn_driver.get(linkedIn_driver.current_url)\n",
    "                            time.sleep(5)\n",
    "\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"Unable to navigate to: {}.\".format(self._profile))\n",
    "                        print(e)\n",
    "\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ## Scientist name\n",
    "                        try:\n",
    "                            name = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-top-card--list li:nth-of-type(1)\").text\n",
    "\n",
    "\n",
    "                        except:\n",
    "                            self.scientist_firstname, self.scientist_lastname = None, None\n",
    "\n",
    "                        else:\n",
    "                            scientist = name.split(\" \")\n",
    "                            \n",
    "                            # if the scientist has one name\n",
    "                            if len(scientist) == 1:\n",
    "                                self.scientist_firstname = scientist[0].strip()\n",
    "                                self.scientist_lastname = None\n",
    "                                return\n",
    "                            \n",
    "                            self.scientist_firstname = scientist[0].strip()\n",
    "                            self.scientist_lastname = scientist[-1].strip()\n",
    "\n",
    "\n",
    "                        ## Title\n",
    "                        try:\n",
    "                            self.scientist_title = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pb5 h2\").text\n",
    "\n",
    "                        except:\n",
    "                            print(\"No title\")\n",
    "                            self.scientist_title = None\n",
    "\n",
    "\n",
    "                        ## Location\n",
    "                        try:\n",
    "                            self.location = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-top-card--list-bullet li:nth-of-type(1)\").text\n",
    "\n",
    "                        except:\n",
    "                            print(\"No location\")\n",
    "                            self.location = None\n",
    "\n",
    "\n",
    "                        ## Connections\n",
    "                        try:\n",
    "                            number = linkedIn_driver.find_element(By.CSS_SELECTOR, '.pv-top-card--list-bullet li:nth-of-type(2) span').text\n",
    "                            self.connections = self.extract_connections(number)\n",
    "\n",
    "                        except Exception as e:\n",
    "\n",
    "                            print(\"No connections\")\n",
    "                            print(e)\n",
    "                            self.connections = None\n",
    "                            \n",
    "\n",
    "                        ## Experience\n",
    "                        try:\n",
    "                            exp_section = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-profile-section.experience-section\").get_attribute('innerHTML')\n",
    "\n",
    "                        except:\n",
    "                            \n",
    "                            print(\"No experience\")\n",
    "                            self.all_experiences = None\n",
    "                            \n",
    "                        else:\n",
    "                            experience = BeautifulSoup(exp_section, 'lxml')\n",
    "                            experience_list = experience.find_all('li', class_=\"pv-entity__position-group-pager\")\n",
    "                            self.all_experiences = []\n",
    "                            for item in experience_list:\n",
    "                                self.all_experiences.extend(self.parse_experience(item, self._scientist_Id))\n",
    "\n",
    "\n",
    "                        ## Education\n",
    "                        try:\n",
    "                            edu_section = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-profile-section.education-section\").get_attribute('innerHTML')\n",
    "\n",
    "                        except:\n",
    "                            print(\"No education\")\n",
    "                            self.all_education = None\n",
    "\n",
    "                        else:\n",
    "                            education = BeautifulSoup(edu_section, 'lxml')\n",
    "                            education_list = education.find_all('li')\n",
    "                            self.all_education = []\n",
    "                            for edu_item in education_list:\n",
    "                                self.all_education.extend(self.parse_education(edu_item, self._scientist_Id))\n",
    "\n",
    "\n",
    "                        ## Certifications\n",
    "                        try:\n",
    "                            cert = linkedIn_driver.find_element(By.CSS_SELECTOR, '.pv-profile-section.certifications-section').get_attribute(\"innerHTML\")\n",
    "\n",
    "                        except:\n",
    "                            print(\"No certifications\")\n",
    "                            self.all_certifications = None\n",
    "\n",
    "                        else:\n",
    "                            certifications = BeautifulSoup(cert, 'lxml')\n",
    "                            cert_list = certifications.find_all('li')\n",
    "                            self.all_certifications = []\n",
    "                            for cert_item in cert_list:\n",
    "                                self.all_certifications.extend(self.parse_certificate(cert_item, self._scientist_Id))\n",
    "\n",
    "                        print(\"Done scraping.\")\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Sign In screen probably did not appear. Check error logs!\")\n",
    "                print(e)\n",
    "\n",
    "            finally:\n",
    "                linkedIn_driver.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Unable to navigate to linkedIn.com. Perhaps you have a bad internet connection. Check error logs!\")\n",
    "            print()\n",
    "            print(e)\n",
    "\n",
    "        finally:\n",
    "            linkedIn_driver.quit()\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        print(\"Saving all credentials...\")\n",
    "\n",
    "        check = self._db_path and self._scientist_Id and self.scientist_firstname and  self.scientist_title and \\\n",
    "            self.scientist_lastname and self.connections and self.location\n",
    "\n",
    "        if (check):\n",
    "            self.insert_scientist(self._db_path, self._scientist_Id, self.scientist_firstname, self.scientist_lastname, \\\n",
    "                self.scientist_title, self.connections, self.location)\n",
    "            print(\"Successfully saved scientist\")\n",
    "\n",
    "        if (check and self.all_experiences):\n",
    "            self.insert_experience(self._db_path, self.all_experiences)\n",
    "            print(\"Successfully saved experiences\")\n",
    "\n",
    "        if (check and self.all_education):\n",
    "            self.insert_education(self._db_path, self.all_education)\n",
    "            print(\"Successfully saved qualifications\")\n",
    "\n",
    "        if (check and self.all_certifications):\n",
    "            self.insert_certification(self._db_path, self.all_certifications)\n",
    "            print(\"Successfully saved certifications\")\n",
    "\n",
    "            \n",
    "    def get_name(self):\n",
    "        \"\"\"Returns the name of the member\"\"\"\n",
    "        return self.scientist_firstname + \" \" + self.scientist_lastname\n",
    "\n",
    "    def get_Id(self):\n",
    "        \"\"\"Returns the Id of the member\"\"\"\n",
    "        return self._scientist_Id\n",
    "\n",
    "    def get_title(self):\n",
    "        \"\"\"Returns the title of the member\"\"\"\n",
    "        return self.scientist_title\n",
    "    \n",
    "    def get_location(self):\n",
    "        \"\"\"Returns the location of the member\"\"\"\n",
    "        return self.location\n",
    "    \n",
    "    def get_experience(self):\n",
    "        \"\"\"Returns the work experiences of the member\"\"\"\n",
    "        return self.all_experiences\n",
    "    \n",
    "    def get_education(self):\n",
    "        \"\"\"Returns all educational qualifications of the member\"\"\"\n",
    "        return self.all_education\n",
    "    \n",
    "    def get_certification(self):\n",
    "        \"\"\"Returns all certifications of the member\"\"\"\n",
    "        return self.all_certifications\n",
    "    \n",
    "    def get_connections(self):\n",
    "        \"\"\"Returns the number of connections of a member\"\"\"\n",
    "        return self.connections\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the <code>ScrapeLinkedin</code> class</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#011f4b;\">Scrape a profile</h4>\n",
    "\n",
    "```bash\n",
    "from ScrapeLinkedin import ScrapeLinkedin\n",
    "\n",
    "profile_link = \"https://www.linkedin.com/in/rebeccanjeri/?source=post_page---------------------------\"\n",
    "rebecca = ScrapeLinkedin(\"yourEmail@email.com\", \"passW0Rd\", profile_link)\n",
    "rebecca.scrape()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#011f4b;\">Save a profile</h4>\n",
    "\n",
    "The save function can only be used after the scrape method is called.\n",
    "\n",
    "```bash\n",
    "rebecca.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#011f4b;\">Some other methods</h4>\n",
    "\n",
    "```bash\n",
    "# get the name of the linkedin account owner\n",
    ">>> rebecca.get_location()\n",
    ">>> 'Seattle, Washington'\n",
    "\n",
    "# get the linkedin owner's experiences\n",
    ">>> rebecca.get_experience()\n",
    "[('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'Greenlight Financial Technology',\n",
    "  None,\n",
    "  'Data Analyst',\n",
    "  'Jul 2020',\n",
    "  'Present',\n",
    "  None),\n",
    " ('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'Textio',\n",
    "  'Full-time',\n",
    "  'Data Scientist',\n",
    "  'Jul 2019',\n",
    "  'Mar 2020',\n",
    "  'Greater Seattle Area'),\n",
    " ('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'Zillow Group',\n",
    "  None,\n",
    "  'Co-Site Lead Black Affinity Network',\n",
    "  'Mar 2019',\n",
    "  'Jun 2019',\n",
    "  'Greater Seattle Area'),\n",
    " ('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'Zillow Group',\n",
    "  None,\n",
    "  'Data Scientist',\n",
    "  'Jan 2018',\n",
    "  'Jun 2019',\n",
    "  'Greater Seattle Area'),\n",
    " ('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'Acheron Analytics',\n",
    "  'Part-time',\n",
    "  'Data Science Writer',\n",
    "  'Jul 2017',\n",
    "  'Dec 2017',\n",
    "  'Seattle, Washington, United States'),\n",
    " ('47965a81-ca69-4c08-ac0d-35da04e332d6',\n",
    "  'SFL Scientific',\n",
    "  'Part-time',\n",
    "  'Data Science Intern',\n",
    "  'Sep 2017',\n",
    "  'Nov 2017',\n",
    "  'Seattle, Washington, United States')]\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building the <code>ScrapeLinkedInM</code> class.</h3>\n",
    "\n",
    "The <code>ScrapeLinkedInM</code> class is created to automate the task of scraping the profiles of <b>multiple</b> users. It is a redesign of the <code>ScrapeLinkedIn</code> class to include a few abstractions. All the scraped data is saved in a lighweight SQLite database specified with the <code>db_path</code> attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Firefox\n",
    "import time\n",
    "from random import randrange\n",
    "from math import ceil\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "class ScrapeLinkedinM:\n",
    "    \"\"\"Scrape the data of multiple linkedin members with your linkedin profile. Note that\n",
    "    this is a breach of the terms and conditions associated with the usage of Linkedin.\n",
    "\n",
    "    Your account WILL BE RESTRICTED if suspicious activity is detected.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    email: String\n",
    "    Your email address eg. yourEmail@email.com\n",
    "\n",
    "    password: String\n",
    "    Your password\n",
    "\n",
    "    profiles: List of strings\n",
    "    A list of linkedin profile links\n",
    "\n",
    "    db_path: String\n",
    "    The path of the SQLite database\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    URL = \"https://linkedin.com\"\n",
    " \n",
    "    def __init__(self, email, password, profiles, db_path=\"ScientistsDB.db\"):\n",
    "        self._email = email\n",
    "        self._password = password\n",
    "        self._db_path = db_path\n",
    "        self._profiles = profiles\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ScrapeLinkedinM\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def insert_scientist(db_path, Id, firstname, lastname, title, connections, location=None):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        data = (Id, firstname, lastname, title, location, connections)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.execute(\"INSERT INTO tblScientist VALUES (?, ?, ?, ?, ?, ?) \", data)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_experience(db_path, experiences):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblExperience VALUES (?, ?, ?, ?, ?, ?, ?)', experiences)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_education(db_path, education):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblEducation VALUES (?, ?, ?)', education)\n",
    "            conn.commit()\n",
    "            conn.close()  \n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def insert_certification(db_path, certifications):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            cur.executemany('INSERT INTO tblCertificates VALUES (?, ?, ?)', certifications)\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception:\n",
    "            conn.close()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_success(link):\n",
    "        with open('success.txt', 'a') as success_file:\n",
    "            success_file.write(link + \"\\n\")\n",
    "     \n",
    "\n",
    "    @staticmethod\n",
    "    def extract_connections(conn_string):\n",
    "        if \"+\" in conn_string:\n",
    "            return int(conn_string.split(\"+\")[0])\n",
    "\n",
    "        elif \" \" in conn_string:\n",
    "            return int(conn_string.split(\" \")[0])\n",
    "\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def parse_experience(self, item, scientist_Id):\n",
    "    \n",
    "        ## Not a timeline item\n",
    "        ul = item.find('ul')\n",
    "\n",
    "        if ul:\n",
    "            # get all timeline experiences\n",
    "            return self.get_more(item, scientist_Id)\n",
    "\n",
    "\n",
    "        # role\n",
    "        try:\n",
    "            role = item.find('h3').text.strip()\n",
    "\n",
    "        except:\n",
    "            role = None\n",
    "\n",
    "\n",
    "\n",
    "        # company\n",
    "        try:\n",
    "            company = item.find('p', class_=\"pv-entity__secondary-title\").contents\n",
    "\n",
    "        except:\n",
    "            company_name, employment_type = None, None\n",
    "\n",
    "        else:\n",
    "            company_name = company[0].strip()\n",
    "\n",
    "            try:\n",
    "                employment_type = company[1].text.strip()\n",
    "\n",
    "            except:\n",
    "                employment_type = None\n",
    "\n",
    "\n",
    "        # start and end dates\n",
    "        find_date_range = item.find('h4', class_=\"pv-entity__date-range\")\n",
    "        date_range = find_date_range.find_all('span')\n",
    "        split_dates = date_range[1].text.split(\"–\")\n",
    "\n",
    "        if(len(split_dates) == 1):\n",
    "            start_date = split_dates[0].strip()\n",
    "            end_date = None\n",
    "\n",
    "        else:\n",
    "            start_date, end_date = split_dates[0].strip(), split_dates[1].strip()\n",
    "\n",
    "\n",
    "        # location\n",
    "        try:\n",
    "            location = item.find('h4', class_=\"pv-entity__location\").find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "\n",
    "        return [(scientist_Id, company_name, employment_type, role, start_date, end_date, location)]\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def parse_education(edu, scientist_Id):\n",
    "        \"\"\"Parses education information\"\"\"\n",
    "\n",
    "        try:\n",
    "            school_name = edu.find('h3', class_ = 'pv-entity__school-name').text\n",
    "            \n",
    "        except:\n",
    "            school_name = None\n",
    "            \n",
    "        try:\n",
    "            list_of_paragraphs = edu.find('div', class_=\"pv-entity__degree-info\").find_all('p')\n",
    "            degree = \" \".join([p.find('span', class_=\"pv-entity__comma-item\").text for p in list_of_paragraphs]).strip()\n",
    "            \n",
    "        except:\n",
    "            degree = None\n",
    "\n",
    "        return [(scientist_Id, school_name, degree)]\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def parse_certificate(cert, scientist_Id):\n",
    "        \"\"\"Parse certificate information\"\"\"\n",
    "\n",
    "        try:\n",
    "            certificate = cert.find('h3', class_=\"t-16\").string.strip()\n",
    "        except:\n",
    "            certificate = None\n",
    "\n",
    "        try:\n",
    "            issuer = cert.find('div', class_=\"pv-certifications__summary-info\").find('p').contents[3].string.strip()\n",
    "        except:\n",
    "            issuer = None\n",
    "\n",
    "        return [(scientist_Id, certificate, issuer)]\n",
    "    \n",
    "    \n",
    "    def get_more(self, list_with_ul, scientist_Id):\n",
    "    \n",
    "        # timeline experiences\n",
    "        tl_exps = []\n",
    "\n",
    "        company_tag, ul_tag = list_with_ul.find('h3'), list_with_ul.find('ul')\n",
    "\n",
    "        if (company_tag and ul_tag) != None:\n",
    "            for list_tag in ul_tag.find_all('li'):\n",
    "                tl_exps.append(self.get_tl_exp(scientist_Id, company_tag, list_tag))\n",
    "\n",
    "            return tl_exps\n",
    "\n",
    "        print(\"No unordered list was detected\")\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tl_exp(scientist_Id, company_tag, item):\n",
    "    \n",
    "        # employement type\n",
    "        employment_type = None\n",
    "\n",
    "        # role\n",
    "        try:\n",
    "            role = item.find('h3').find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            role = None\n",
    "\n",
    "\n",
    "        # company\n",
    "        try:\n",
    "            company_name = company_tag.find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            company_name = None\n",
    "\n",
    "\n",
    "        # start and end dates\n",
    "        find_date_range = item.find('h4', class_=\"pv-entity__date-range\")\n",
    "        date_range = find_date_range.find_all('span')\n",
    "        split_dates = date_range[1].text.split(\"–\")\n",
    "\n",
    "        if(len(split_dates) == 1):\n",
    "            start_date = split_dates[0].strip()\n",
    "            end_date = None\n",
    "\n",
    "        else:\n",
    "            start_date, end_date = split_dates[0].strip(), split_dates[1].strip()\n",
    "\n",
    "\n",
    "        # location\n",
    "        try:\n",
    "            location = item.find('h4', class_=\"pv-entity__location\").find_all('span')[1].text.strip()\n",
    "\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "\n",
    "        return (scientist_Id, company_name, employment_type, role, start_date, end_date, location)\n",
    "\n",
    "    \n",
    "\n",
    "    def scrape_save(self):    \n",
    "        \"\"\"Scrape the data of each member\"\"\" \n",
    "        try:\n",
    "            ## navigate to the linkedIN profile\n",
    "            linkedIn_driver = Firefox(executable_path='./geckodriver')\n",
    "            linkedIn_driver.get(self.URL)\n",
    "\n",
    "            # Sign In...\n",
    "            try:\n",
    "                toggle_button = linkedIn_driver.find_element(By.CLASS_NAME, 'nav__button-secondary')\n",
    "                toggle_button.click()\n",
    "\n",
    "                time.sleep(2)\n",
    "\n",
    "                ## fill the form\n",
    "                try:\n",
    "                    ## find the username input \n",
    "                    username = linkedIn_driver.find_element(By.ID, 'username')       \n",
    "\n",
    "                    ## find the password input\n",
    "                    password = linkedIn_driver.find_element(By.ID, 'password')\n",
    "\n",
    "                    ## find the sign In button\n",
    "                    sign_in = linkedIn_driver.find_element(By.XPATH, '//button[@type=\"submit\"]')\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('An error occured, probably one of the inputs was not found. Check error log!')\n",
    "                    print()\n",
    "                    print(e)\n",
    "\n",
    "                ## no exception was raised, meaning all inputs were found\n",
    "                else:\n",
    "                    print(\"Entering your username...\")\n",
    "                    username.send_keys(self._email)\n",
    "\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    print('Entering your password...')\n",
    "                    password.send_keys(self._password)\n",
    "\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    print('Signing you in...')\n",
    "                    sign_in.click()\n",
    "                    print('Successfully signed in.')\n",
    "\n",
    "                    time.sleep(5)\n",
    "\n",
    "                    self.counter = 0\n",
    "\n",
    "                    \n",
    "                    ## start scraping all profiles\n",
    "                    for profile in self._profiles:\n",
    "\n",
    "                        self._scientist_Id = str(uuid.uuid4())\n",
    "                        \n",
    "                        ## navigate to the new profile\n",
    "                        try:             \n",
    "                            linkedIn_driver.get(profile)\n",
    "                            print(\"Scraping {}...\".format(profile))\n",
    "\n",
    "                            # wait for the page to finish loading\n",
    "                            time.sleep(5)\n",
    "\n",
    "                            # for redirects\n",
    "                            if (profile != linkedIn_driver.current_url):\n",
    "                                linkedIn_driver.get(linkedIn_driver.current_url)\n",
    "                                time.sleep(5)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(\"Unable to navigate to: {}.\".format(profile))\n",
    "                            print()\n",
    "                            print(e)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            ## Scientist name\n",
    "                            try:\n",
    "                                name = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-top-card--list li:nth-of-type(1)\").text\n",
    "\n",
    "                            except:\n",
    "                                self.scientist_firstname, self.scientist_lastname = None, None\n",
    "\n",
    "                            else:\n",
    "                                scientist = name.split(\" \")\n",
    "\n",
    "                                # if the scientist has one name\n",
    "                                if len(scientist) == 1:\n",
    "                                    self.scientist_firstname = scientist[0].strip()\n",
    "                                    self.scientist_lastname = None\n",
    "                                    return\n",
    "\n",
    "                                self.scientist_firstname = scientist[0].strip()\n",
    "                                self.scientist_lastname = scientist[1].strip()\n",
    "\n",
    "\n",
    "                            ## Title\n",
    "                            try:\n",
    "                                self.scientist_title = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pb5 h2\").text\n",
    "\n",
    "                            except:\n",
    "                                print(\"No title\")\n",
    "                                self.scientist_title = None\n",
    "\n",
    "\n",
    "                            ## Location\n",
    "                            try:\n",
    "                                self.location = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-top-card--list-bullet li:nth-of-type(1)\").text\n",
    "\n",
    "                            except:\n",
    "                                print(\"No location\")\n",
    "                                self.location = None\n",
    "\n",
    "\n",
    "                            ## Connections\n",
    "                            try:\n",
    "                                number = linkedIn_driver.find_element(By.CSS_SELECTOR, '.pv-top-card--list-bullet li:nth-of-type(2) span').text\n",
    "                                self.connections = self.extract_connections(number)\n",
    "\n",
    "                            except Exception as e:\n",
    "\n",
    "                                print(\"No connections\")\n",
    "                                print(e)\n",
    "                                self.connections = None\n",
    "\n",
    "\n",
    "\n",
    "                            ## Experience\n",
    "                            try:\n",
    "                                exp_section = linkedIn_driver.find_element(By.CSS_SELECTOR, \".pv-profile-section.experience-section\").get_attribute('innerHTML')\n",
    "\n",
    "                            except:\n",
    "                                print(\"No experience\")\n",
    "                                self.all_experiences = None\n",
    "                                \n",
    "                            else:\n",
    "                                experience = BeautifulSoup(exp_section, 'lxml')\n",
    "                                experience_list = experience.find_all('li', class_=\"pv-entity__position-group-pager\")\n",
    "                                self.all_experiences = []\n",
    "                                for item in experience_list:\n",
    "                                    self.all_experiences.extend(self.parse_experience(item, self._scientist_Id))\n",
    "\n",
    "\n",
    "                            ## Education\n",
    "                            try:\n",
    "                                edu_section = linkedIn_driver.find_element(By.CSS_SELECTOR, \".education-section\").get_attribute('innerHTML')\n",
    "\n",
    "                            except:\n",
    "                                print(\"No education\")\n",
    "                                self.all_education = None\n",
    "\n",
    "                            else:\n",
    "                                education = BeautifulSoup(edu_section, 'lxml')\n",
    "                                education_list = education.find_all('li')\n",
    "                                self.all_education = []\n",
    "                                for edu_item in education_list:\n",
    "                                    self.all_education.extend(self.parse_education(edu_item, self._scientist_Id))\n",
    "\n",
    "\n",
    "                            ## Certifications\n",
    "                            try:\n",
    "                                cert = linkedIn_driver.find_element(By.CSS_SELECTOR, '.certifications-section').get_attribute(\"innerHTML\")\n",
    "\n",
    "                            except:\n",
    "                                print(\"No certifications\")\n",
    "                                self.all_certifications = None\n",
    "\n",
    "                            else:\n",
    "                                certifications = BeautifulSoup(cert, 'lxml')\n",
    "                                cert_list = certifications.find_all('li')\n",
    "                                self.all_certifications = []\n",
    "                                for cert_item in cert_list:\n",
    "                                    self.all_certifications.extend(self.parse_certificate(cert_item, self._scientist_Id))\n",
    "\n",
    "                            print(\"Done scraping\")\n",
    "\n",
    "                            ## save the profile\n",
    "                            self.save_success(profile)\n",
    "\n",
    "                            ## increase the counter\n",
    "                            self.counter += 1\n",
    "\n",
    "                            if (self.all_education and self.all_experiences):\n",
    "                                ## save attributes \n",
    "                                self.save()\n",
    "\n",
    "                            if(self.counter >=  50):\n",
    "                                print(\"You've scraped more than {} profiles today. Please quit the scraper\".format(self.counter))\n",
    "\n",
    "                            ## sleep\n",
    "                            sleep = randrange(60, 200, 1)\n",
    "                            print(\"Sleeping for approximately {} minutes\".format(ceil(sleep / 60)))\n",
    "                            time.sleep(sleep)\n",
    "                            print()\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Sign In screen probably did not appear. Check error logs!\")\n",
    "                print(e)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Unable to navigate to linkedIn.com. Perhaps you have a bad internet connection. Check error logs!\")\n",
    "            print()\n",
    "            print(e)\n",
    "\n",
    "        finally:\n",
    "            linkedIn_driver.quit()\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Save the data of a linkedin member\"\"\"\n",
    "        \n",
    "        print(\"Saving all credentials...\")\n",
    "\n",
    "        check = self._db_path and self._scientist_Id and self.scientist_firstname and  self.scientist_title and \\\n",
    "            self.scientist_lastname and self.connections and self.location\n",
    "\n",
    "        if (check):\n",
    "            self.insert_scientist(self._db_path, self._scientist_Id, self.scientist_firstname, self.scientist_lastname, \\\n",
    "                self.scientist_title, self.connections, self.location)\n",
    "            print(\"Successfully saved scientist\")\n",
    "\n",
    "        if (check and self.all_experiences):\n",
    "            self.insert_experience(self._db_path, self.all_experiences)\n",
    "            print(\"Successfully saved experiences\")\n",
    "\n",
    "        if (check and self.all_education):\n",
    "            self.insert_education(self._db_path, self.all_education)\n",
    "            print(\"Successfully saved qualifications\")\n",
    "\n",
    "        if (check and self.all_certifications):\n",
    "            self.insert_certification(self._db_path, self.all_certifications)\n",
    "            print(\"Successfully saved certifications\")\n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the <code>ScrapeLinkedInM</code> class.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "unscraped_urls = [\"profileOfLinkedInUser1\", \"profileOfLinkedInUser2\", \"profileOfLinkedInUser3\"]\n",
    "scrape_multiple = ScrapeLinkedinM(\"yourEmail@email.com\", \"passW0Rd\", unscraped_urls)\n",
    "scrape_multiple.scrape_save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Cleaning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data cleaning processes are implemented within all the classes thus, no subsequent cleaning process is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Modelling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single table <b>tblScientist</b> was created to store the personal information of each member. Three other tables tblCertificates, tblExperience and tblEducation are also created to store the certification, experience and educational qualification details of each member. Each of these tables are linked to tblScientist using referential integrity techniques (foreign key). The structured data was stored in a serverless database (SQLite)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight: 500\"> The Scientist </p>\n",
    "\n",
    "```sql\n",
    "create table tblScientist(\n",
    "    Id text primary key,\n",
    "    firstname text not null,\n",
    "    lastname text not null,\n",
    "    title text not null,\n",
    "    location text null,\n",
    "    numOfConnections int not null\n",
    ")\n",
    "```\n",
    "<br/>\n",
    "\n",
    "<p style=\"font-weight:500;\">Experience</p>\n",
    "\n",
    "```sql\n",
    "create table tblExperience(\n",
    "    scientistId text not null,\n",
    "    companyName text not null,\n",
    "    employementType text null,\n",
    "    role text not null,\n",
    "    startDate date null,\n",
    "    endDate date null,\n",
    "    location varchar(50) null,\n",
    "    FOREIGN KEY(scientistId) REFERENCES tblScientist(Id)\n",
    ")\n",
    "```\n",
    "<br/>\n",
    "\n",
    "<p style=\"font-weight:500;\">Certificates</p>\n",
    "\n",
    "```sql\n",
    "create table tblCertificates(\n",
    "    scientistId text,\n",
    "    certName text not null,\n",
    "    issuer text not null,\n",
    "    FOREIGN KEY(scientistId) REFERENCES tblScientist(Id)\n",
    ")\n",
    "```\n",
    "<br/>\n",
    "\n",
    "\n",
    "<p style=\"font-weight:500\">Education</p>\n",
    "\n",
    "```sql\n",
    "create table tblEducation(\n",
    "    scientistId text not null,\n",
    "    schoolName text not null,\n",
    "    degree text null,\n",
    "    FOREIGN KEY(scientistId) REFERENCES tblScientist(Id)\n",
    ")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screen Shot 2020-11-11 at 6.00.19 PM.png\" alt=\"the data\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing the Hypothesis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Assumptions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A postgraduate degree is a <b>master's degree</b> or a <b>PhD</b>.\n",
    "2. Professionals who say they have a postgraduate degree actually have a postgraduate degree.\n",
    "3. Most data science professionals actually have linkedin profiles.\n",
    "4. The data scientists in the sample are actually data scientists.\n",
    "5. The sample is a simple random sample.\n",
    "6. Data scientists call themselves \"data scientists\" on their linkedin profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientist</th>\n",
       "      <th>University</th>\n",
       "      <th>Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62093db0-7628-4198-9048-82da9efb6863</td>\n",
       "      <td>Birla Institute of Technology and Science, Pilani</td>\n",
       "      <td>master of science - ms data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62093db0-7628-4198-9048-82da9efb6863</td>\n",
       "      <td>JNTUH College of Engineering Hyderabad</td>\n",
       "      <td>b.tech electrical and electronics engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9442cb86-9853-4e7e-b9b1-ab145d3d71a4</td>\n",
       "      <td>National Institute of Technology Kurukshetra</td>\n",
       "      <td>bachelor of technology - btech computer science 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17aadfcd-9fa9-4767-b24b-f23110a78cec</td>\n",
       "      <td>National Institutes of Health</td>\n",
       "      <td>postdoctoral fellow virtual colonoscopy comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17aadfcd-9fa9-4767-b24b-f23110a78cec</td>\n",
       "      <td>Polytechnic University of Bucharest</td>\n",
       "      <td>doctor of philosophy (phd) engineering sciences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Scientist  \\\n",
       "0  62093db0-7628-4198-9048-82da9efb6863   \n",
       "1  62093db0-7628-4198-9048-82da9efb6863   \n",
       "2  9442cb86-9853-4e7e-b9b1-ab145d3d71a4   \n",
       "3  17aadfcd-9fa9-4767-b24b-f23110a78cec   \n",
       "4  17aadfcd-9fa9-4767-b24b-f23110a78cec   \n",
       "\n",
       "                                          University  \\\n",
       "0  Birla Institute of Technology and Science, Pilani   \n",
       "1             JNTUH College of Engineering Hyderabad   \n",
       "2       National Institute of Technology Kurukshetra   \n",
       "3                      National Institutes of Health   \n",
       "4                Polytechnic University of Bucharest   \n",
       "\n",
       "                                              Degree  \n",
       "0                master of science - ms data science  \n",
       "1      b.tech electrical and electronics engineering  \n",
       "2  bachelor of technology - btech computer science 8  \n",
       "3  postdoctoral fellow virtual colonoscopy comput...  \n",
       "4    doctor of philosophy (phd) engineering sciences  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "education_df = pd.read_csv(\"education.csv\")\n",
    "\n",
    "# change the case of strings in the degree column\n",
    "education_df['Degree'] = education_df['Degree'].str.lower()\n",
    "\n",
    "education_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utility Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPostGrad(qualification):\n",
    "    \"\"\"Checks if a degree is a postgraduate degree or not\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    qualification: str\n",
    "    The degree\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    True if the qualification is a postgraduate degree\n",
    "    False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    qualification = str(qualification)\n",
    "    degrees = [\"master\", \"msc\", \"ms\", \"m.sci\", \"msci\", \"m.sc\", \"philosophy\", \"meng\", \"m.eng\", \"mhs\", \"mtech\", \\\n",
    "               \"m.tech\", \"m.a\", \"ma \" \"mba\", \"phd\", \"ph.d\", \"mmath\", \"m.s\", \"msee\", \"mse\", \"mstat\", \"dphil\", \\\n",
    "              \"mphys\", \"mres\", \"mds\", \"m.mgt\", \"m.e.\"]\n",
    "    \n",
    "    # filtering...\n",
    "    if \"micromasters\" in qualification:\n",
    "        return False\n",
    "    \n",
    "    if \"bachelor\" in qualification:\n",
    "        return False\n",
    "    \n",
    "    if \"graduate certificate\" in qualification:\n",
    "        return False\n",
    "    \n",
    "    for degree in degrees:\n",
    "        if degree in qualification:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def includes(df, word: str):\n",
    "    \"\"\"Find degrees that contain a certain word\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    dataframe of educational qualifications\n",
    "    \"\"\"\n",
    "    filtered = df.loc[df['Degree'].str.contains(word)]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_type(degree: str) -> bool:\n",
    "    \n",
    "    \"\"\"Determines the type of a degree\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    degree: str\n",
    "    \n",
    "    Degree\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    degree_type: str\n",
    "    \n",
    "    The type of the degree\n",
    "    \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Degrees can be classified into 8 categories namely:\n",
    "        - Science\n",
    "        - Engineering\n",
    "        - Technology\n",
    "        - Business\n",
    "        - Mathematics\n",
    "        - Arts\n",
    "        - PhD\n",
    "        - Others\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    degree_type = \"\"\n",
    "    \n",
    "    # sciences\n",
    "    economics = re.search('economi\\w+', degree)\n",
    "    science = re.search('scien\\w+', degree)\n",
    "    info_tech = re.search('information tech\\w+', degree)\n",
    "    info_sys = re.search('information sys\\w+', degree)\n",
    "    stats = re.search('statisti.+', degree)\n",
    "    \n",
    "    # engineering\n",
    "    engineering = re.search('engine\\w+', degree)\n",
    "    \n",
    "    # tech\n",
    "    m_tech = re.search('m\\.te\\w+', degree)\n",
    "    mtech = re.search('mtec.+', degree)\n",
    "    has_mtech = m_tech or mtech\n",
    "    \n",
    "    # business\n",
    "    analytics = re.search('analyt\\w+', degree)\n",
    "    business = re.search('mba.*', degree)\n",
    "    has_business = analytics or business\n",
    "    \n",
    "    # mathematics\n",
    "    mathematics = re.search('math.+', degree)\n",
    "    econometrics = re.search('econome\\w+', degree)\n",
    "    has_math = mathematics or econometrics\n",
    "    \n",
    "    # arts\n",
    "    arts = re.search('art\\w+', degree)\n",
    "    \n",
    "    # phd\n",
    "    phd = re.search('phd.+', degree)\n",
    "    ph_d = re.search('ph.+', degree)\n",
    "    \n",
    "    has_phd = phd or ph_d\n",
    "    \n",
    "    \n",
    "    #-----\n",
    "    # PHD\n",
    "    #-----\n",
    "    \n",
    "    if has_phd:\n",
    "        degree_type = \"phd\"\n",
    "        return degree_type\n",
    "    \n",
    "    \n",
    "    #-------------\n",
    "    # MATHEMATICS\n",
    "    #-------------\n",
    "    \n",
    "    if has_math:\n",
    "        degree_type=\"math\"\n",
    "        return degree_type\n",
    "        \n",
    "        \n",
    "    #-------------\n",
    "    # ENGINEERING\n",
    "    #-------------\n",
    "    \n",
    "    if engineering:\n",
    "        degree_type=\"engineering\"\n",
    "        return degree_type\n",
    "        \n",
    "    \n",
    "    #------------\n",
    "    # TECHNOLOGY\n",
    "    #------------\n",
    "    \n",
    "    if has_mtech:\n",
    "        degree_type = \"technology\"\n",
    "        return degree_type\n",
    "        \n",
    "    \n",
    "    #----------\n",
    "    # BUSINESS\n",
    "    #----------\n",
    "    \n",
    "    if has_business:\n",
    "        degree_type=\"business\"\n",
    "        return degree_type\n",
    "        \n",
    "    \n",
    "    #------\n",
    "    # ARTS\n",
    "    #------\n",
    "    \n",
    "    if arts:\n",
    "        degree_type=\"arts\"\n",
    "        return degree_type\n",
    "        \n",
    "        \n",
    "    #----------\n",
    "    # SCIENCES\n",
    "    #----------\n",
    "\n",
    "    if science or economics or info_tech or info_sys or stats:\n",
    "        degree_type=\"science\"\n",
    "        return degree_type\n",
    "    \n",
    "    \n",
    "    return \"other\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Finding postgraduate degrees</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df['isPostGrad'] = education_df['Degree'].apply(isPostGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgrad_df = education_df[education_df['isPostGrad'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are approximately 895 professionals with at least one postgraduate degree.\n"
     ]
    }
   ],
   "source": [
    "postgrads = postgrad_df['Scientist'].unique().shape[0]\n",
    "print(\"There are approximately {} professionals with at least one postgraduate degree.\".format(postgrads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientist</th>\n",
       "      <th>University</th>\n",
       "      <th>Degree</th>\n",
       "      <th>isPostGrad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6bd1eb73-752a-4443-bbb0-644f11579048</td>\n",
       "      <td>University of Melbourne - Melbourne Business S...</td>\n",
       "      <td>master’s degree business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>f6ad8e25-fd42-4271-b10d-af0aaf26ad75</td>\n",
       "      <td>SVKM's Narsee Monjee Institute of Management S...</td>\n",
       "      <td>master of business administration - mba techno...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2eaa73ac-3e35-456a-95b9-cbde505127cc</td>\n",
       "      <td>University of California, Davis</td>\n",
       "      <td>master of science in business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>e9935136-2cd8-40ee-957f-9d4666db7643</td>\n",
       "      <td>Washington University in St. Louis</td>\n",
       "      <td>b.s., m.s. electrical engineering</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6990fbf5-e043-446e-a7b1-92c2a4780560</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>master of science - ms business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>eae11211-62a9-41f4-95d7-553df85addd1</td>\n",
       "      <td>La Trobe University</td>\n",
       "      <td>master of business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>3a4a55a3-ae10-4e9d-9749-7ddd406473af</td>\n",
       "      <td>La Trobe University</td>\n",
       "      <td>master's degree business information managemen...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>bde8700d-4936-4d59-a1c9-087119d63f56</td>\n",
       "      <td>Lund University School of Economics and Manage...</td>\n",
       "      <td>master of science in business and economics (s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>60329f6c-8dd1-4569-a485-b0e7073ac971</td>\n",
       "      <td>The University of Texas at Austin</td>\n",
       "      <td>master's degree business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>be8b4311-f438-4d3e-b01a-845dabcd66d3</td>\n",
       "      <td>University of Melbourne</td>\n",
       "      <td>master's degree business analytics</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Scientist  \\\n",
       "20    6bd1eb73-752a-4443-bbb0-644f11579048   \n",
       "27    f6ad8e25-fd42-4271-b10d-af0aaf26ad75   \n",
       "115   2eaa73ac-3e35-456a-95b9-cbde505127cc   \n",
       "134   e9935136-2cd8-40ee-957f-9d4666db7643   \n",
       "145   6990fbf5-e043-446e-a7b1-92c2a4780560   \n",
       "...                                    ...   \n",
       "2643  eae11211-62a9-41f4-95d7-553df85addd1   \n",
       "2665  3a4a55a3-ae10-4e9d-9749-7ddd406473af   \n",
       "2712  bde8700d-4936-4d59-a1c9-087119d63f56   \n",
       "2802  60329f6c-8dd1-4569-a485-b0e7073ac971   \n",
       "2804  be8b4311-f438-4d3e-b01a-845dabcd66d3   \n",
       "\n",
       "                                             University  \\\n",
       "20    University of Melbourne - Melbourne Business S...   \n",
       "27    SVKM's Narsee Monjee Institute of Management S...   \n",
       "115                     University of California, Davis   \n",
       "134                  Washington University in St. Louis   \n",
       "145                    National University of Singapore   \n",
       "...                                                 ...   \n",
       "2643                                La Trobe University   \n",
       "2665                                La Trobe University   \n",
       "2712  Lund University School of Economics and Manage...   \n",
       "2802                  The University of Texas at Austin   \n",
       "2804                            University of Melbourne   \n",
       "\n",
       "                                                 Degree  isPostGrad  \n",
       "20                   master’s degree business analytics        True  \n",
       "27    master of business administration - mba techno...        True  \n",
       "115             master of science in business analytics        True  \n",
       "134                   b.s., m.s. electrical engineering        True  \n",
       "145           master of science - ms business analytics        True  \n",
       "...                                                 ...         ...  \n",
       "2643                       master of business analytics        True  \n",
       "2665  master's degree business information managemen...        True  \n",
       "2712  master of science in business and economics (s...        True  \n",
       "2802                 master's degree business analytics        True  \n",
       "2804                 master's degree business analytics        True  \n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the presence of some unwanted strings\n",
    "includes(postgrad_df, 'b.s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting postgrads for EDA\n",
    "postgrad_df.to_csv('postgrads.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Formula Sheet</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Formula Sheet.png\" alt=\"formula sheet\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hypothesis Test of Proportions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fixed alpha test with <b style=\"font-size: 2.5rem; font-weight:700\">$\\alpha = 0.1$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight: 700; font-size:2rem;\">$H_{o}: p = 0.70$</p>\n",
    "\n",
    "70% of data science professionals possess at least one postgraduate degree. The proportion is the same and any sample difference is due to <b>sampling error</b>.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<p style=\"font-weight: bold; font-size:2rem;\">$H_{A}: p \\neq 0.70$ </p>\n",
    "\n",
    "70% of data science professionals <b>do not</b> possess at least one postgraduate degree. The proportion has changed and <b>any sample difference is real</b>.\n",
    "\n",
    "\n",
    "<b><i>This hypothesis test is therefore a two-tailed test.</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check for assumptions</h3>\n",
    "\n",
    "1. The sample is random\n",
    "2. The sample size is less than 10% of the population size.\n",
    "3. Each sample is independent.\n",
    "4. $np_{o} \\geq 10$ and $n(1-p_{o}) \\geq 10$ where $p_{o}$ is the value of p in $H_{o}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample, $895$ of $1200$ professionals were found to have postgraduate degrees.\n",
    "\n",
    "\n",
    "<h4>Sample proportion</h4>\n",
    "\n",
    "<p style=\"font-weight: bold; font-size: 2rem; text-align: center\">$\\hat{p} = \\frac {895} {1200} = 0.745$</p>\n",
    "\n",
    "How unusual is the observed $\\hat{p}$?\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h4>Test Statistic for a test of proportions</h4>\n",
    "\n",
    "<p style=\"font-size: 2rem; text-align: center; font-weight:600\">$z = \\frac {statistic - parameter} {SD(statistic)} $</p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<p style=\"font-size:2rem; text-align:center;\">$SD(\\hat{p}) = \\sqrt \\frac {0.7 \\times 0.3} {1200} = 0.013229$</p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<p style=\"font-size: 2rem; text-align: center;\">$\\therefore z = \\frac {0.745 - 0.7} {0.013229} = 3.40$</p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Using the Z-score table,\n",
    "<p style=\"font-size:2rem; text-align:center\">$P- value = 0.9994$</p>\n",
    "\n",
    "Where\n",
    "\n",
    "- $\\hat{p}$ is the statistic\n",
    "- <b>$p_{o}$</b> is the parameter.\n",
    "- $SD(statistic)$ is the standard deviation of the statistic which can be calculated using the formula sheet above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting the actual proportion</h2>\n",
    "\n",
    "In this section, statistical methods are used to estimate the true population proportion of data scientists that possess at least one postgraduate degree with a 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Confidence Intervals</h3>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<b style=\"font-size: 1.5rem\">CI</b> = <b>statistic</b> $\\pm$ <b>critical value</b> $\\times$ <b>S.E(statistic)</b>\n",
    "\n",
    "<b>statistic</b> = $\\hat{p}$\n",
    "\n",
    "<b>critical value</b> at 95% Confidence = $1.960$\n",
    "\n",
    "<b style=\"font-size: 2rem; font-weight: bold\">$S.E(\\hat{p}) = \\sqrt \\frac {\\hat{p}\\hat{q}} {n}$</b>\n",
    "\n",
    "So,\n",
    "\n",
    "<p style=\"font-size:2rem; text-align:center;\">$S.E(\\hat{p}) = \\sqrt \\frac {0.745 \\times 0.255} {1200} = 0.01258222$</p>\n",
    "\n",
    "$\\therefore$ The proportion of data scientists that possess a postgraduate degree is <b style=\"font-size: 2rem; font-weight: bold\">$0.745 \\pm 0.025$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The P-value is almost 1.\n",
    "\n",
    "\n",
    "- If the population proportion is $0.70$, it is highly likely (0.9994) to observe 895 out of 1200 professionals that possess a postgraduate degree.\n",
    "\n",
    "\n",
    "- There is insufficient evidence that the proportion of professionals that possess at least one postgraduate degrees is not 70% with a 10% level of significance.\n",
    "\n",
    "\n",
    "- Looks like most data scientists indeed possess a postgraduate degree of some sort.\n",
    "\n",
    "\n",
    "- Around 72% to 77% of data scientists possess at least a postgraduate degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recommendations</h2>\n",
    "\n",
    "A better degree-filtering algorithm can be developed for a more accurate determination of postgraduate degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Scientist</th>\n",
       "      <th>University</th>\n",
       "      <th>Degree</th>\n",
       "      <th>isPostGrad</th>\n",
       "      <th>type of degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62093db0-7628-4198-9048-82da9efb6863</td>\n",
       "      <td>Birla Institute of Technology and Science, Pilani</td>\n",
       "      <td>master of science - ms data science</td>\n",
       "      <td>True</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>17aadfcd-9fa9-4767-b24b-f23110a78cec</td>\n",
       "      <td>Polytechnic University of Bucharest</td>\n",
       "      <td>doctor of philosophy (phd) engineering sciences</td>\n",
       "      <td>True</td>\n",
       "      <td>phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>17aadfcd-9fa9-4767-b24b-f23110a78cec</td>\n",
       "      <td>Polytechnic University of Bucharest</td>\n",
       "      <td>master's degree electrical engineering</td>\n",
       "      <td>True</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>47e210c3-f3c9-4e69-849d-5ff27cbd4e8f</td>\n",
       "      <td>University of St. Thomas</td>\n",
       "      <td>master's degree software engineering</td>\n",
       "      <td>True</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>10568a61-2c82-4a00-9ded-837b498803fd</td>\n",
       "      <td>RMIT University</td>\n",
       "      <td>master of analytics data analytics</td>\n",
       "      <td>True</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             Scientist  \\\n",
       "0           0  62093db0-7628-4198-9048-82da9efb6863   \n",
       "1           4  17aadfcd-9fa9-4767-b24b-f23110a78cec   \n",
       "2           5  17aadfcd-9fa9-4767-b24b-f23110a78cec   \n",
       "3           6  47e210c3-f3c9-4e69-849d-5ff27cbd4e8f   \n",
       "4          13  10568a61-2c82-4a00-9ded-837b498803fd   \n",
       "\n",
       "                                          University  \\\n",
       "0  Birla Institute of Technology and Science, Pilani   \n",
       "1                Polytechnic University of Bucharest   \n",
       "2                Polytechnic University of Bucharest   \n",
       "3                           University of St. Thomas   \n",
       "4                                    RMIT University   \n",
       "\n",
       "                                            Degree  isPostGrad type of degree  \n",
       "0              master of science - ms data science        True        science  \n",
       "1  doctor of philosophy (phd) engineering sciences        True            phd  \n",
       "2           master's degree electrical engineering        True    engineering  \n",
       "3             master's degree software engineering        True    engineering  \n",
       "4               master of analytics data analytics        True       business  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "postgrad_df = pd.read_csv('postgrads.csv')\n",
    "grouped = postgrad_df.groupby('type of degree').count()['Scientist']\n",
    "postgrad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = grouped.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAIECAYAAAD1kDyAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYLGV99vHvzSKgICgcCQKKIoq4AR5wi7siKopRUXFDQ0Tjnqhxia+iiVui4hYXFATcETdEjIALKgnCQVFZVFAwcGQ5roAiCvzeP55noB3ncOYsPT1T5/u5rr6mu7qq+qme7r7rWaoqVYUkSRqWdSZdAEmStOYZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9NWJJvJPmHSZdjSpItk3wzyeVJ3jaL+Z+R5NtzUTZJs2fAS0CS85NcmeSKJL9J8qUk2066XKsiyWFJ/n01VnEA8EvgplX1kjVUrIlzR0RrGwNeut6jqmpjYCvgEuDdq7KSJOut0VKt3GuvuwZWc2vgrJrwWbAm+T5KQ2DAS9NU1R+Bo4CdpqYleWSS7yW5LMkFSQ4ceW67JJVk/yT/B3xtpvUm2TvJ6X0dP02y58jTt05yUm8WPy7JFiPLfTrJxUl+15vO7zTy3GFJ3pfk2CS/B/YHngL8S2+N+OJyynLvJKf2dZ6a5N5T6wP2G1n+ITMsu3mSo/t2nAJsP+35HZMcn+TXSX6c5AnTlv1iX/bUJP8+Wqvu7+PzkpwDnDOL9W2Q5K1J/i/JJUnen2SjGcp8R+D9wL36dv02yW59mXVH5ntsku/3+wcmOSrJp/r/5btJ7jYy7y2TfCbJsiTnJXnhyHO7J1nSt/OSJG+f6f8gjVVVefO21t+A84GH9Ps3Bg4Hjhh5/gHAXWg7xXel1fAf05/bDijgCOAmwEYzrH934HfAQ/s6tgZ27M99A/gpcHtgo/74zSPL/j2wCbAB8A7g9JHnDuvrvU9f74Z92r/fwLbeHPgN8DRgPWDf/njzkXXe0PKfBI7s23pnYCnw7f7cTYALgGf2de9Ca+7faWTZT/b3eKc+77dH1l3A8b2MG81ifQcBR/f5NwG+CLxpOeV+xuhr9WlnAQ8fefw54CX9/oHAn4HHA+sDLwXO6/fXAU4DXgPcCLgt8DPgYX3Z/wWe1u9vDNxz0p9xb2vfzRq8dL3PJ/kt1wfxf049UVXfqKofVtW1VfUD4BPA/actf2BV/b6qrpxh3fsDh1bV8X0dS6vqRyPPf7iqftKXPRLYeeS1D62qy6vqKlro3C3JpiPLfqGqTurr/eMstvORwDlV9ZGqurqqPgH8CHjUihbstd3HAa/p23oGbWdoyl7A+VX14b7u7wGfAfYZWfa1VfWHqjpr2rJT3lRVv+7vxQ2tL7TxAv/U578ceCPwpFm8B1MOB57at+3mwMOAj488f1pVHVVVfwbeTtuBuiewG7Coql5fVX+qqp8BHxx57T8Dt0uyRVVdUVUnr0SZpDXCPi7peo+pqhN6EO0NnJhkp6q6OMk9gDfTaqw3otWmPz1t+QtuYN3bAsfewPMXj9z/A63WNxWobwD2ARYB1/Z5tqDtiKzodWdyS+Dn06b9nNaqsCKLaL8bo685uq5bA/foO0pT1gM+spxlZyr76LQVre/GwGkt6wEIsDLjED4KnJ3kJsATgG9V1UUzlaWqrk1yIe39K+CW08q1LvCtfn9/4PXAj5KcB7yuqo5ZiXJJq82Al6apqmuAzyb5APC3tP74jwPvoTXn/jHJO2gh+xeL3sBqL2BaX/UsPZm2s/EQWjfCprTm9IzMM/11VzQ47he04Bx1K+C/Z1GeZcDVtB2WqRaIW408fwFwYlU9dPqCfWflamAb4Cd98kxHKoyW/4bWtw5wJXCnqlo6i7L/1ftSVUuT/C/wWFqXxfumzXJd+frrbUN7/64GzquqHWZ8oapzgH37Mo8FjkqyeVX9fhbllNYIm+iladLsDdwMOLtP3gT4dQ/33WnBuzIOAZ6Z5MFJ1kmydZIdZ7HcJsBVwK9otdU3zmKZS2h9wstzLHD7JE9Osl6SJ9L6w1dYw5za+QEOTHLjJDvRBuVNOaav+2lJ1u+33ZLccYZldwSevoKXvKH1XUtrFj8oyS0A+vv6sOWs6xJgmyQ3mjb9COBfaGMsPjvtubv3gXfrAS+m/S9OBk4BLk/y8iQbJVk3yZ2T7NbL8dQki3oZp2r51yLNIQNeut4Xk1wBXEZrFt+vqs7szz0XeH2Sy2kDq45cmRVX1Sm0gWIH0ZrWT+Sva9EzOYLWBL6UNiBsNn25hwA79ZHin5+hLL+i9W2/hLbj8C/AXlX1y1msG+D5tC6Ei2kD8j48su7LgT1ofdG/6PO8hdalMbXspn36R2hjGa5a3gvNYn0vB84FTk5yGXACcIflrO5rwJnAxUlGt/VztP/F56rqD9OW+QLwRK4flPjYqvpz31nZizZW4jzawL8P9W0D2BM4s3+e3gk8aTljM6SxSdVED3WVtBZL8hbgb6pqvxXOPN5y/BR4dlWdMDLtQOB2VfXUiRVMWg3W4CXNmX5M+117N8jutMFon5twmR5H65+f8fwF0kLlIDtJc2kTWrP8LWl94m+jNYNPRJJv0MYfPK33l0uDYRO9JEkDZBO9JEkDZMBLkjRAC7oPfosttqjttttu0sWQJGnOnHbaab+sqkUrmm9BB/x2223HkiVLJl0MSZLmTJLpp5qekU30kiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gCNPeCTrJvke0mO6Y9vk+Q7Sc5N8qkkN+rTN+iPz+3PbzfuskmSNFRzUYN/EXD2yOO3AAdV1e2A3wD79+n7A7/p0w/q80mSpFUw1oBPsg3wSOBD/XGABwFH9VkOBx7T7+/dH9Off3CfX5IkraRx1+DfAfwLcG1/vDnw26q6uj++ENi6398auACgP/+7Pv9fSHJAkiVJlixbtmycZZckacEaW8An2Qu4tKpOW5PrraqDq2pxVS1etGiFl8OVJGmtNM7rwd8HeHSSRwAbAjcF3glslmS9XkvfBlja518KbAtcmGQ9YFPgV2MsnyRJgzW2GnxVvbKqtqmq7YAnAV+rqqcAXwce32fbD/hCv390f0x//mtVVeMqnyRJQzaJ4+BfDvxzknNpfeyH9OmHAJv36f8MvGICZZMkaRDG2UR/nar6BvCNfv9nwO4zzPNHYJ+5KI8krW0W0kFJNt6uGZ7JTpKkAZqTGrwkaX7Y4/XHTLoIy3Xca/aadBEGxRq8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJAzS2gE+yYZJTknw/yZlJXtenH5bkvCSn99vOfXqSvCvJuUl+kGTXcZVNkqShW2+M674KeFBVXZFkfeDbSb7cn3tZVR01bf6HAzv02z2A9/W/kiRpJY2tBl/NFf3h+v1WN7DI3sARfbmTgc2SbDWu8kmSNGRj7YNPsm6S04FLgeOr6jv9qTf0ZviDkmzQp20NXDCy+IV9miRJWkljDfiquqaqdga2AXZPcmfglcCOwG7AzYGXr8w6kxyQZEmSJcuWLVvjZZYkaQjmZBR9Vf0W+DqwZ1Vd1JvhrwI+DOzeZ1sKbDuy2DZ92vR1HVxVi6tq8aJFi8ZddElrqSQL5ibNZJyj6Bcl2azf3wh4KPCjqX71tE/lY4Az+iJHA0/vo+nvCfyuqi4aV/kkSRqycY6i3wo4PMm6tB2JI6vqmCRfS7IICHA68Jw+/7HAI4BzgT8Azxxj2SRpVvZ4/TGTLsJyHfeavSZdBM1jYwv4qvoBsMsM0x+0nPkLeN64yiNJ0trEM9lJkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQM0toBPsmGSU5J8P8mZSV7Xp98myXeSnJvkU0lu1Kdv0B+f25/fblxlkyRp6MZZg78KeFBV3Q3YGdgzyT2BtwAHVdXtgN8A+/f59wd+06cf1OeTJEmrYGwBX80V/eH6/VbAg4Cj+vTDgcf0+3v3x/TnH5wk4yqfJElDNtY++CTrJjkduBQ4Hvgp8NuqurrPciGwdb+/NXABQH/+d8DmM6zzgCRLkixZtmzZOIsvSdKCNdaAr6prqmpnYBtgd2DHNbDOg6tqcVUtXrRo0WqXUZKkIZqTUfRV9Vvg68C9gM2SrNef2gZY2u8vBbYF6M9vCvxqLsonSdLQjHMU/aIkm/X7GwEPBc6mBf3j+2z7AV/o94/uj+nPf62qalzlkyRpyNZb8SyrbCvg8CTr0nYkjqyqY5KcBXwyyb8D3wMO6fMfAnwkybnAr4EnjbFskiQN2tgCvqp+AOwyw/Sf0frjp0//I7DPuMojSdLaxDPZSZI0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QGML+CTbJvl6krOSnJnkRX36gUmWJjm93x4xsswrk5yb5MdJHjauskmSNHTrjXHdVwMvqarvJtkEOC3J8f25g6rqraMzJ9kJeBJwJ+CWwAlJbl9V14yxjJIkDdLYavBVdVFVfbffvxw4G9j6BhbZG/hkVV1VVecB5wK7j6t8kiQN2Zz0wSfZDtgF+E6f9PwkP0hyaJKb9WlbAxeMLHYhN7xDIEmSlmPsAZ9kY+AzwIur6jLgfcD2wM7ARcDbVnJ9ByRZkmTJsmXL1nh5JUkagrEGfJL1aeH+sar6LEBVXVJV11TVtcAHub4Zfimw7cji2/Rpf6GqDq6qxVW1eNGiReMsviRJC9Y4R9EHOAQ4u6rePjJ9q5HZ/g44o98/GnhSkg2S3AbYAThlXOWTJGnIxjmK/j7A04AfJjm9T3sVsG+SnYECzgeeDVBVZyY5EjiLNgL/eY6glyRp1Ywt4Kvq20BmeOrYG1jmDcAbxlUmSZLWFp7JTpKkATLgJUkaIANekqQBMuAlSRogA16SpAEy4CVJGiADXpKkATLgJUkaIANekqQBMuAlSRogA16SpAEy4CVJGiADXpKkATLgJUkaIANekqQBmlXAJ7nLuAsiSZLWnNnW4N+b5JQkz02y6VhLJEmSVtusAr6q7gs8BdgWOC3Jx5M8dKwlkyRJq2zWffBVdQ7wauDlwP2BdyX5UZLHjqtwkiRp1cy2D/6uSQ4CzgYeBDyqqu7Y7x80xvJJkqRVsN4s53s38CHgVVV15dTEqvpFklePpWSSJGmVzTbgHwlcWVXXACRZB9iwqv5QVR8ZW+kkSdIqmW0f/AnARiOPb9ynSZKkeWi2Ab9hVV0x9aDfv/F4iiRJklbXbAP+90l2nXqQ5O7AlTcwvyRJmqDZ9sG/GPh0kl8AAf4GeOLYSiVJklbLrAK+qk5NsiNwhz7px1X15/EVS5IkrY7Z1uABdgO268vsmoSqOmIspZIkSatlVgGf5CPA9sDpwDV9cgEGvCRJ89Bsa/CLgZ2qqsZZGEmStGbMdhT9GbSBdZIkaQGYbQ1+C+CsJKcAV01NrKpHj6VUkiRptcw24A8cZyEkSdKaNdvD5E5Mcmtgh6o6IcmNgXXHWzRJkrSqZnu52GcBRwEf6JO2Bj4/rkJJkqTVM9tBds8D7gNcBlBV5wC3GFehJEnS6pltwF9VVX+aepBkPdpx8JIkaR6abcCfmORVwEZJHgp8Gvji+IolSZJWx2wD/hXAMuCHwLOBY4FXj6tQkiRp9cx2FP21wAf7TZIkzXOzPRf9eczQ515Vt13jJZIkSattZc5FP2VDYB/g5mu+OJIkaU2YVR98Vf1q5La0qt4BPHLMZZMkSatotk30u448XIdWo7/BZZNsS7uc7Ja05v2Dq+qdSW4OfIp2bfnzgSdU1W+SBHgn8AjgD8Azquq7K7U1kiQJmH0T/dtG7l9ND+YVLHM18JKq+m6STYDTkhwPPAP4alW9OckraCP0Xw48HNih3+4BvK//lSRJK2m2o+gfuLIrrqqLgIv6/cuTnE07xe3ewAP6bIcD36AF/N7AEf2a8ycn2SzJVn09kiRpJcy2if6fb+j5qnr7CpbfDtgF+A6w5UhoX0xrwocW/heMLHZhn2bAS5K0klZmFP1uwNH98aOAU4BzVrRgko2BzwAvrqrLWld7U1WVZKVOeZvkAOAAgFvd6lYrs6gkSWuN2Qb8NsCuVXU5QJIDgS9V1VNvaKEk69PC/WNV9dk++ZKppvckWwGX9ulLgW2nvebS6eusqoOBgwEWL17s+fAlSZrBbE9VuyXwp5HHf+L6pvUZ9VHxhwBnT2vCPxrYr9/fD/jCyPSnp7kn8Dv73yVJWjWzrcEfAZyS5HP98WNoA+RuyH2ApwE/THJ6n/Yq4M3AkUn2B37O9aPxj6UdIncu7TC5Z86ybJIkaZrZjqJ/Q5IvA/ftk55ZVd9bwTLfBrKcpx88w/xFu+68JElaTbNtoge4MXBZVb0TuDDJbcZUJkmStJpmFfBJXks7Vv2VfdL6wEfHVShJkrR6ZluD/zvg0cDvAarqF8Am4yqUJElaPbMN+D/1PvICSHKT8RVJkiStrtkG/JFJPgBsluRZwAnAB8dXLEmStDpmO4r+rUkeClwG3AF4TVUdP9aSSZKkVbbCgE+yLnBCv+CMoS5J0gKwwib6qroGuDbJpnNQHkmStAbM9kx2V9DOSHc8fSQ9QFW9cCylkiRJq2W2Af/ZfpMkSQvADQZ8kltV1f9V1YrOOy9JkuaRFfXBf37qTpLPjLkskiRpDVlRwI9eLOa24yyIJElac1YU8LWc+5IkaR5b0SC7uyW5jFaT36jfpz+uqrrpWEsnSZJWyQ0GfFWtO1cFkSRJa87KXA9ekiQtEAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQNkwEuSNEAGvCRJA2TAS5I0QAa8JEkDZMBLkjRABrwkSQM0toBPcmiSS5OcMTLtwCRLk5zeb48Yee6VSc5N8uMkDxtXuSRJWhuMswZ/GLDnDNMPqqqd++1YgCQ7AU8C7tSXeW+SdcdYNkmSBm1sAV9V3wR+PcvZ9wY+WVVXVdV5wLnA7uMqmyRJQzeJPvjnJ/lBb8K/WZ+2NXDByDwX9mmSJGkVzHXAvw/YHtgZuAh428quIMkBSZYkWbJs2bI1XT5JkgZhTgO+qi6pqmuq6lrgg1zfDL8U2HZk1m36tJnWcXBVLa6qxYsWLRpvgSVJWqDmNOCTbDXy8O+AqRH2RwNPSrJBktsAOwCnzGXZJEkakvXGteIknwAeAGyR5ELgtcADkuwMFHA+8GyAqjozyZHAWcDVwPOq6ppxlU0LU5JJF2HWqmrSRZC0lhtbwFfVvjNMPuQG5n8D8IZxlUeSpLXJ2AJeGpc9Xn/MpIuwXMe9Zq9JF0GSAE9VK0nSIBnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDdB6ky6AxifJpIswa1U16SJI0qBYg5ckaYCswa8F9nj9MZMuwnId95q9Jl0ESRoka/CSJA2QAS9J0gAZ8JIkDdDYAj7JoUkuTXLGyLSbJzk+yTn978369CR5V5Jzk/wgya7jKpckSWuDcdbgDwP2nDbtFcBXq2oH4Kv9McDDgR367QDgfWMslyRJgze2gK+qbwK/njZ5b+Dwfv9w4DEj04+o5mRgsyRbjatskiQN3Vz3wW9ZVRf1+xcDW/b7WwMXjMx3YZ8mSZJWwcQG2VU7ddlKn74syQFJliRZsmzZsjGUTJKkhW+uA/6Sqab3/vfSPn0psO3IfNv0aX+lqg6uqsVVtXjRokVjLawkSQvVXAf80cB+/f5+wBdGpj+9j6a/J/C7kaZ8SZK0ksZ2qtoknwAeAGyR5ELgtcCbgSOT7A/8HHhCn/1Y4BHAucAfgGeOq1ySJK0NxhbwVbXvcp568AzzFvC8cZVFkqS1jWeykyRpgLyanKQ1IsmkizBrrdFQGjZr8JIkDZA1eElr1B6vP2bSRViu416z16SLIM0Za/CSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAebEZaUK8vKqkcbIGL0nSAFmDlybMy6tKGgdr8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDdB6k3jRJOcDlwPXAFdX1eIkNwc+BWwHnA88oap+M4nySZK00E2yBv/Aqtq5qhb3x68AvlpVOwBf7Y8lSdIqmE9N9HsDh/f7hwOPmWBZJEla0CYV8AUcl+S0JAf0aVtW1UX9/sXAljMtmOSAJEuSLFm2bNlclFWSpAVnIn3wwN9W1dIktwCOT/Kj0SerqpLUTAtW1cHAwQCLFy+ecR5JktZ2E6nBV9XS/vdS4HPA7sAlSbYC6H8vnUTZJEkagjkP+CQ3SbLJ1H1gD+AM4Ghgvz7bfsAX5rpskiQNxSSa6LcEPpdk6vU/XlX/neRU4Mgk+wM/B54wgbJJkjQIcx7wVfUz4G4zTP8V8OC5Lo8kSUM0nw6TkyRJa4gBL0nSABnwkiQNkAEvSdIAGfCSJA2QAS9J0gAZ8JIkDZABL0nSABnwkiQNkAEvSdIATepysfNOPzf+glHllXIlSctnDV6SpAGyBj/NHq8/ZtJFuEHHvWavSRdBkrQAWIOXJGmADHhJkgbIgJckaYAMeEmSBsiAlyRpgAx4SZIGyICXJGmADHhJkgbIgJckaYAMeEmSBsiAlyRpgAx4SZIGyICXJGmADHhJkgbIgJckaYAMeEmSBsiAlyRpgAx4SZIGyICXJGmA1pt0ASRJWllJJl2EWauqibyuNXhJkgbIGrwkacHa4/XHTLoIy3Xca/aa6Otbg5ckaYAMeEmSBsiAlyRpgAx4SZIGyICXJGmADHhJkgbIgJckaYAMeEmSBmjeBXySPZP8OMm5SV4x6fJIkrQQzauAT7Iu8F/Aw4GdgH2T7DTZUkmStPDMq4AHdgfOraqfVdWfgE8Ce0+4TJIkLTiZ1FVuZpLk8cCeVfUP/fHTgHtU1fNnmn/x4sW1ZMmSNfXaa2Q9c2U2/7eFtE1uz/zm9sxvbs/8tqZzNslpVbV4RfMtuIvNJDkAOKA/vCLJjydZnlnYAvjlml7pBD/cbs8suD1rjNszC27PGrNQtufWs5lpvgX8UmDbkcfb9GnXqaqDgYPnslCrI8mS2expLRRuz/zm9sxvbs/8NrTtmW998KcCOyS5TZIbAU8Cjp5wmSRJWnDmVQ2+qq5O8nzgK8C6wKFVdeaEiyVJ0oIzrwIeoKqOBY6ddDnWoAXTnTBLbs/85vbMb27P/Dao7ZlXo+glSdKaMd/64CVJ0hpgwEtrkSR+5+ehJBtOugwan36W1jnnl32O+QM7uQ/7XEqyznz5XyfZJsnOAFV17aTLs6akmRfv8apIPzg6yTuBN41OG7K1YRunq6prpu7P5fYv2C/HQtF/6K/7h1bVtUnWT/KIJHebZNnm2tT7MPphH6qqunYqTJPcKsn6c/n6U6+XZAPgRcCj++M7J3lIkpv2xwv2x7aaqff4DgttW+r6AVCfAO4zbdrgTO2MrQ3bOPJ4aiduuyRfhrndfgN+jJLcG3jy6D80yf8DfgA8BRh0s1zfubmutl5V1Xdunp7k6CR3mGT51pTRbRz5Qu+a5K1JvkT7Ab/ZHJbn1vRAr6qrgO8DGyU5BDgceCnwzrkqz5owU4tIkm2TPKb/cP4DsNlkSrdiSdadofwbJXkWsAewbf+9GJRp3/+pnbFdkjwxyS364wW1YzZdb0laF/5iG5PkydPC/KokN5/Lshnwa9i0L/Evgf9M8p9JvpRkE2AX4JFV9ZSq+s5kSjk3ei32Gmh9jL02+VHgQcBQRrizAAAX90lEQVTHgAsmWb5VNRLiU1/q61ok+k7M3wDvBi4E3g7cBRhba83oD8yIhyR5X5LXAH+k7WBsXlV3Bx4LPCDJrRdKbWqqRSTJLZJs1yc/GvgP4OiqellV/WZiBZxB/8y/JclGVXXNDN0jrweeAJwM/Bx4QV9uQQce/EVtfbRpevMkHwH+E7gtcGSSmyyUz+Dy9Jakqd+5OyV5AXBj4LlJXpRkI+DOwM+r6tc20S8g0/sB+4/Qxkn+ifYD9Cfa6Xf37/f/SPtgvyHJG5M8pa9nQf8veg1lKvim/m7fQ+Y44L7A7Wjnen4ZcCJw9UL6MUuyRdq1EO4F7ccryY2SPDvJMUke2YP2LsBPquodVfVV2rG1D047O+MaN/oD020MPA24H3BqVR0F/Az4VZLNq+oPwBLm4ZUa+4/hTNPvmOS/aefIeEGSfYEPA5cC5/Xv4bz4LPXvwrpV9UfgccDDktw6ySFJXpDk5r0md0vgJVV1HK0F4r5JNlyIgTf9vR/pinxKknf0ydsB3wb+DjiF9vl89JwWdDWN/s6NTLtRktcm+RHwBtpv/Y607+CWwD8DP+L63w2b6BeKqX7AkVB7E/BF2pf3MNr17a+qqot7c+lLgRfTAu4XwKuTbLzQBz/1Gkr12kol2YK2p/5D4NlVdXw/K+H/AR8B/hU4DXj25Eq9YtOa334JHFtV/9Of+1daDf2OtFMqP4cWmtcCfxxpjvsCrda8aA2VZ3pT752T/EeS45LsAZwNPBX4Ki3IAX4C/Jb2wwPwKeCRSebFya6SbJrk7cDfj0zbsv9dF7g/8G/9POGX0mq/19C2azvaOT0mGoyjtdaRHa43Aq8E/pFW7tsB/0b7X9wB+HWSDarqDOBK4DFzXvDVkOX0q/dWrK/Svg/f7ZPvDzwP+AbwTOChVfWJOSvsKkiySZKtpx6P/M7dIslUl9CdgHvTduxfCPwYeHRVnQe8ldZK8wjg7N6KO2cM+FU0EugPSHIkrVZ+T9qH+e60H6Nf0vo879s/8ACXVNW3gf8FLgeOBxbMHvtMzcF92tOTfAE4JMli4PfADsBvgK1609XNquqZwN5V9QLgzcCDpq9vPpnW/HYH2rUSDuzh8yvaXvmH+kWQPg08CziJdqGkB/TVLKU1ka9SM/20nYypHcpFSW6W5DbAy4GfAv9CC5LHAl/riz+2/z2VFoh37I8/SwvG26xKmdaEJLdMcl+AqvodcCZwnyTPTfJ94FNJdu7v/1OBVyb5FvC3wCv7DvNx/fHE+9/7/2XDJI9K8vUk7wHOotXiflpVrwTeA9y+TzsNeGbfDoCLuf5KmQvCSJ/zXZM8Ib1fHXg6cHpVPaGqjujTvkPb+X1oVT21qr6a5G7zZSdzOV4PvCyte5EkuyX5DvB54KAkt6V9rzavqj9X1VQF5pZJdqiqX9N28J4C3LyqLp/L3zsDfhX1vbi70vrNDgX+H/Bx4AxgA/ppgKvqElrz6B590TskeTptoN2ewEeq6vdzXPyVNvUlnKE5GGBxv/0L8Dng32l9bO+g7bk+jjao6zN9/jsn2Y/2of/JDOubiEwbyNWDdbMkj0tyKK2pbQvgFrSxFJ8FrgD+3Hf4PgNsD9wUOAR4cpITaD/qZwAPm1rvypRr6j3v5duktxz8hNYcuGtVPQ04j/ZjdCdg/6q6DDiHFibQao+/p33+/qb/MO9WVees7Pu0Oqa9xwUcmORvkjyS1oy5MXBX4B60Vq5npfW5H097X+9XVY+qqqOSbEVrHdkZ2Gkut2MmSW4JfI9WC38dcBnts78u8Oc+2y9o3/19aIfGbZfkqCTH9mWPnt5CMx8sp+VovST3T3Iw7fv997TPOrQWig37fBsBVNVJtJ24N/Tv1HtoFaCd52gzVmiG8P007Tu9qD/3D8Dbq+retP/vc2mtYl9Ncp++zJWMjLupdvr1/0fbqZvTo4jm3QdpIamqHwDPALYC3gVsTvunnkT7x095O/D4JD+n1US+DOxYVftW1alzWuiVkHZ412HQLgTUp22f5B1JPpRktz7rI4GNgIcDr6YNLvxDVR1SVU+rqpfQapIb9x+JJwMPBN5dVa+e261avpGBXBsn2aU3O24PvA34XVU9u6o+TauRL66qS2kDBe8HrNt31L4LvKqqPg+8FnhTVT2Ctle/rL/OSrXYJNk5ydv6ut8G/KqqbkarER2QZFtat88HaMF4uz7tK8Ctk5wDvKo/fltVXZwkfSdgTo28x6G1HuzUt+tOtEGJVwLr9/7rI4HQfiy/RPuB3KZ/Bt8EPK+qrqTtZH9vrrdluqr6Ba38v66qb9AGWv4YuBrYq8/2B1qrw5Or6nxat87XgTdX1QurjduYF911SXbvO1GjLUfrJ7l3r9HelHbFz7tX1QOrak/gb5LcD7gEWCfJrfr/iLQxKAfQPrf70P7fe1bVkhlefiJGWuu26Y//h1ZZ260/d1dayx3A+2itsLcALqK1pEHbqb6A61vLADYFjpnr1koDfvU9gDZo5Mm0ZqknAkcw0tTW9+BeCtyjql5VVctGmuXmlfzloW1LabVWenPwq4D302qPFwJvSzue+he01oiifWGfWlXn9aB8YJIPAf8DfLz/eL20qp5RVV+e4827TmY+tO3mST5B6yN8XpKXVtVptLJfmOsHyZ0N3KL/CHwOeAjtCwztR/2n/f5PgDsl+QZtrMEnV6Gcj+3l+S7ts7Ur1zdHf4E2WvddwNeq6ku0bpGNgRdV1VQt/x+r6nVVdXJVXQyTOxY57RCpz9N2Rv4O+BDwnar6j6r6Oe092qyX8UxaTfD2PQTeQ9ueTwM3odX+qKqvz6NWsA9yfVfMb2iB/iVg1yQ79ff9h8BXekvKn6vqv6rqm/DX582YayPfhZvSPkvr9ccbJPk32uC4/Wnv/ZW0lpWLeusFtDEfu/f5Cnhzkuck+Rrwuqr6fVUdVlVPqqo3T30e59r01rqR6c9N8l3go2kDItel/f8emORWtEGeU8F9Pq32fg5twOfFSc6g7ZBeSu96TfK3tNa18+a6tdKAX33bAldU62//Da0WewHwp6m9X4Cq+smkPswro9ewrkmyTv8w7pHk8GqHIG0JbFxV762qA2nbe29aF8R3aIcrXZQ24vn5tB/hLWmB99Cqekd/jYmPORjZU99+pDz3Ar5YbSDXV4EXpp2M6ERal8MGfb7v0voSH0yrFW9KC1Wq6qSqene//2fa3v6Lq+oeVXXuKhT1ZFoT7+lV9WPajw1JFlXVb2k/OHcDNk87WuHVtIFdJ/YyfK+qTliF113jktwMeAWtzIfQjqw4iTauYWqMylnANUke1B+fCeyS5K79fX1hVe3aa7tz2r0wS58H7pjk7r0V4r60/9n/Ag+FVtOvqteO/h7k+sFq107i+zHVBD/12r1159O0HUporZOX0QbKvYzW9bAvbdDsufQR4rTWyXsA6wMvob0fuwNvrDYGYV4YaUnaMMmNAZLcjtYatw9tsNxdadv6KVoL08a0HZj908Ya3IL2vpxfbQzJ84HdaK1lm9EqSNBal+5SVR+Zq+2bMp8HNywUp9NGI59AOwTuP4EfVtXtJlusldObbCvJQ4H9gE1oI2DPAl7Va69fBjZLctuq+hmtX/ketGORdwPe0X/EN6U1r15WVStda12TRn84p017Hu0wlt8m+QztS3xP4DFJ/p628/u6qvp+kstpP2jbAGdX1flJftHXewWt9WL6a/ZWzfrY6pS/qn6RNnjxkbSw+xatWfRWtCb/k2mtRYfSmkWP7E3F89GmtObLp1fVVUn+i1YD+hVt+w6h/SieSRuf8TXgv2k7iD8E6Ds181bfwf0h8L4kP6aFxHuB/ap3c03pgXptX27Om+Vn2KmoHlz7AkfRdtBf1rsWt6cd0jZ1lMiraeey2IBWodmFNgblq7RWv22rDTg7st8mYqbvf59+T9pI/vvSdtL/iXaUyy5V9dO+3Ltp4yTeSmul3L2qDks77fPBtO6ld9DGv0B7v95EG1Pwefp2T7R1qaq8reaN9iF5MrDBpMsyi7KGdkjR6LRt+9/FtCa3pwBb92nr0Gog+9AGmL0beFp/7l60L/RO/fGtgPtPevuWM/1GwI36/R1oTb2hHfFwIq1m+QjaQK8tR5a7Zf97LG0Pfd3+eN1p619njNu0N3DiyHZMjdZfr/9/tp/052qW2zE1nmH3kc/Ph2g/tN+njSN4BW2n8fGTLu9qbOeetKMWbjubz+akb1PlovUh/5AW3Leh9bEfSBs8uy2tpr7zyHKb9+/QY2lna9yuT7/JPNim+/XP0qJp09el7difz/WHrh7Xf/NuR+v2umOfd5e+XZvTdqKPAW7cn9tiOa+71aS3ffRmE/0aUFXfqqqP1zzsV5/qN576W91IX9s2wFFJ7kg73OhUWv/RhkluU23P9wvAvtW6IX5G+wGmqv6XduKKP/TH/1dVJ87pBo5IO//6h5PcfmTaPZJ8nFbznWoi3JbWn30ILWC+R+v7PY22LfdMsnWSVwD/1vsj/4VWO74GrjvJzV9cY2CMm/Z12uCle1XVn2hjPL5RVVdXq339dAXLzxdLaUcdPLU/vojW9fFR2liGbYHPVtV3qp2cZ6H6H1oT7VTT7/owP7qm4C/62e+X5FPAh3rL3W7AfaudZfM82gCyk/u0C2hdU/ukHRL3DFrg3YsWkC+p1rKVmlCNNe0kNFOt0tfQuq7uluSVSU5K8hxa68P3aTvKP6mqZbRzWNyR1hpxFtf/TtydNlj4V7Ta+FuqnSSK/lv4Vye+qaqLxr2dKyPz5DOnMejh/eWqukt/vF5VXZ3kQNqo8IN6/9PraD++R9BGft+MFnR70gYO/pRWU38A7YvwYOBd1UaRT1T/cqVGzgEN3LSqfpfkZbSTTLyR1nf2NdpRD9C6FT5SVe+ftr49aYezPYC2s/OhqjplDjblBqWd/vLkmsdHXcxG2nny3w9cRfsBflO1cwgMSh+D8p35+v/qzczvpR3edgytS+5bwJ2rdZ9s0P/emtba9UFad+Tf07pTlgEfrnYWvnklyY2q6k+9C2h94Ne0k4+9lfZ9PiTJ+2ndbe9MsgttEOzHaEc9vJFWe/8d7eiG46a6MCeyQavBgB+4tIudnEj7Aj+BNuL6lrS+pkf0QNyDNrL9odOWPYg2nuDQtGNdP1JV35rbLZidJFtV6//cidbNcCvaD9F/0Ab4XZDkLbQv+7G0oP9zVb0iycNoI7oPrapTpnaEJrMlw5d2kqDbA0uqH0KluZXkIbRjug+jHRGzDu3skkdUOxpjar4NaTXabapq/z5tot+P/ps1NQh4dPqDaCd6WkQbp3JfWrfPq6rqxN7q8Nyq2j3JU4G9qupJfdkP0JrtD6qqP6Yd4TDvB0WviE30w/cxWt/xhbQa+a2BrWknm5kaQf4j2gCb+6WdV3m/tOPf70u7CAZVdcAkwz0zX01soyT/kHZ++KV9pPVZtEFaj6A1lX6NNtIfWrDvSmsmfi+wZZJTaCNlz6DVUKjrj/n/qyuAafVV1SW9W8twn5yTaIMy96F9/l9F6y55cZL7JHlNH9x5Le2QxpfCdYNxJxLuU03hvZdx6iiYdfrf29IGzn6eNn7jYlqr3fm0fneq6jBg+76D+U3a9//+ffWHA5+oduQD1c8VkXl8ls3Z8Mdr+L5OO1RtSe9Xez+t73MDWq0VWjPWprQve2ijQE8E7lPtYikTk+vPoHfd9dVHvBt4PG3MwFlcfx7zLwNPHRkzsEtfx4m0gYL3qaqfVjtt7qOr6iFV9Z7ev32dmvkKYNKCV1VXVtWLqmr/qtqPNnDz67RxKS+j/R4cWFV/qnZY32/6cnPa5Nt37PcYqYxMXfTpzUk+y/VdbrejDYj9WFX9su+InEf7bbhL2tE90HbiX15thP9Huf7kU/9T7cRD1xndkVioPExu4Hqz9edpl2g9jdavdCXtNKu79wFom9MOi1labaDgP02qvHDdSWiu7V+wqdr0HWktESfTWiVuRyv3o6rqz0mW0fbeX0zbtmekXQziNOA5aWem+x5tFPdZU681tafODE1+0pClXRDq/rRT6+4GPKfaGfgmemjrqGrHqm9DO/b8MNqhqtvSWh8+AHwwbQDxb2mni92qqi4a2RH5Fq2r7ja083b8K/30zVV1yOhrLdR+9htiwK8dPkW7Lv07aU1uf0vrq/oz7fC+46udsW1emNb8thOtOf2btMvt7kGrhb+X1vR+TdqlOU9K8qckD6mqE9KOU38mbXDQ7Wk/AFQ7q+D01yvaqFtpbXIV7Yp2JwLPmmqenod2pZ3q9xraaPapk2u9mNat8Kt+25h2DP/b007VvCNthP8DaZUaqupkWiUB+KtzEQwq3MFBdmuFJBvTRsl/kzZC/vvAK6rq8okWbAb9kKJn0c4IeCpt9OtpwB49uB9OO2b1WbQTaxzfjwbYkLZ9P66qpyV5BO2c5l+Y4TUGt6cuDVWSHYGDaNf0OAk4gdYS+SHg89UOWd2Q1grx77SLKt2S1pL3b9O/66OhPnTW4NcCVXVFkhfRLgJz3PS+5nnmCbQToryYdnKJvWl751PXZD6Xth0Pox3S969pp5Pdgjagbq/+Bf6LmvpoqBvu0sJRVT9KchTtwjz/QxtEe1pVfQYgyZOAn1fVt5LsS2uxO3H0e54JnzVwUqzBa15J8l7ayP1raFfk+y/aZScfU1W79eP29wUeWFVPTTu15uNopzS9Na0p77VV9fu1aU9dGrIkW9Na63bqffJH0EbI70o7Ic8rql2OdnSZ68byzHV55wtr8Jo3evN8aE3w76NdfW9Zn/6yqWNT087xfbMkN6cNnDmJdpjPvYC3Vj+TluEuDUNVLU1yapIv01rwjqB1O/5HVf1oOcus9eNqrMFrXknyPGDHqnpBf3w/2kV83gUcXlXvG21u74fRPYzW53ZEzcPTBUtafWmXpN0XOKVGzsnhUTDLZ8BrXklyE9oI+Q1p/e6b0k6V+aWqunxauNsEL62lRk98M+myzFcGvOadPiJ2Z9rV3745Mt3R79Jazh372TPgNe/149xtfpOkleCpajVvjTTBGe6StJKswUuSNEDW4CVJGiADXpKkATLgJUkaIANeWoCSXJPk9CRnJvl+kpf0q+9NXJKd+8V+JE2Qp6qVFqYrq2pngH4+/o8DN6VdgGe1rIHDEncGFgN/dWleSXNnXuzxS1p1VXUp7cp7z0+zbpL/7Ofu/kGSZ0M7QUiS9yb5UZLjkxyb5PH9ufOTvCXJd4F9kmyf5L+TnJbkW/2SnSRZlOQzfd2nJrnPaFmS3Ah4PfDE3sLwxCTnJFk0UoZz+3oOS/L+JEuS/CTJXn2e5ZV/qyTf7Os9I8l95+gtlhYka/DSAFTVz/rVs25Bu8Tu7/rV9zYATkpyHHB3YDtgpz7f2cChI6v5VVXtCpDkq8BzquqcJPegnT74QcA7gYOq6ttJbgV8BbjjSDn+lOQ1wOKqen5f1460Cwi9A3gI8P1+ESF6eXanXSL460luBzx9OeV/LPCVqnpD39Ybr8n3UBoaA14anj2Au07Vzmnn898B+Fvg0/00nxcn+fq05T4FkGRj4N7Ap3sIA2zQ/z4E2Glk+k2TbFxVV9xAeQ4FvkAL+L8HPjzy3JG9POck+Rmw4w2U/1Tg0H51wc9X1ekrfiuktZcBLw1AktsC1wCX0i65+4Kq+sq0eVY08O33/e86wG+n+vinWQe4Z1X9cbZlq6oLklyS5EG02vpTRp+ePvvyyg/XXV3wkcBhSd5eVUfMthzS2sY+eGmB6/3b7wfe0y/G8xXgH3tNlyS371fpOwl4XO8H3xJ4wEzrq6rLgPOS7NOXT5K79aePA14w8toz7QRcDmwybdqHgI/SWhBGB/Dt08uzPXBb4MfLK3+SWwOXVNUH+/p2nc37I62tDHhpYdpo6jA54ARa8L6uP/ch4Czgu0nOAD5Aa637DHBhf+6jwHeB3y1n/U8B9k/yfeBMWr8+wAuBxX3w21nAc2ZY9uu0ZvzTkzyxTzsa2Ji/bJ4H+D/gFODLtD7/P95A+R8AfD/J94An0sYDSFoOz0UvrUWm+suTbE4L1vtU1cVz8LqLaYPz7jsy7TDgmKo6atyvL62N7IOX1i7HJNkMuBHwb3MU7q8A/pG/7HuXNGbW4CVJGiD74CVJGiADXpKkATLgJUkaIANekqQBMuAlSRogA16SpAH6/0VDhfDJjilkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.bar(degrees, grouped.values, color=\"steelblue\", linewidth=\"2\", edgecolor='k')\n",
    "plt.xticks(rotation=20)\n",
    "plt.xlabel('Degree types')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bar chart of degree types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business: 8.956%\n",
      "Arts: 2.794%\n",
      "Engineering: 11.997%\n",
      "Math: 6.491%\n",
      "PhD: 28.595%\n",
      "Science: 32.457%\n",
      "Technology: 1.068%\n",
      "Others: 7.642%\n"
     ]
    }
   ],
   "source": [
    "# Proportions\n",
    "total = grouped.sum()\n",
    "business = grouped.loc['business']/total\n",
    "arts = grouped.loc['arts']/total\n",
    "engineering = grouped.loc['engineering']/total\n",
    "math = grouped.loc['math']/total\n",
    "other = grouped.loc['other']/total\n",
    "phd = grouped.loc['phd']/total\n",
    "science = grouped.loc['science']/total\n",
    "tech = grouped.loc['technology']/total\n",
    "\n",
    "print(\"Business: {:.3f}%\".format(business*100))\n",
    "print('Arts: {:.3f}%'.format(arts*100))\n",
    "print(\"Engineering: {:.3f}%\".format(engineering*100))\n",
    "print(\"Math: {:.3f}%\".format(math*100))\n",
    "print(\"PhD: {:.3f}%\".format(phd*100))\n",
    "print(\"Science: {:.3f}%\".format(science*100))\n",
    "print(\"Technology: {:.3f}%\".format(tech*100))\n",
    "print(\"Others: {:.3f}%\".format(other*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusions</h2>\n",
    "\n",
    "- Even though most professionals have <b>Master of Science</b> degrees ($32.6\\%$), it appears that many professionals also possess <b>PhD's</b> ($28.477\\%$).\n",
    "\n",
    "\n",
    "- Interestingly, only $6.50\\%$ of the professionals studied for a <b>Math</b> degree. \n",
    "\n",
    "\n",
    "- A substantial percentage ($12.02\\%$) of data scientists also possess an <b>Engineering</b> postgraduate degree.\n",
    "\n",
    "\n",
    "- There are not many data scientists that have a <b>Technology</b> postgraduate degree. Only $1.07\\%$ professionals fall in this category.\n",
    "\n",
    "\n",
    "- Lastly, only $2.798\\%$ of professionals have <b>Art</b> postgraduate degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.333px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
